#!/usr/bin/env python3
"""
ì˜¬ë°”ë¥¸ CSV ë°ì´í„° ì¶”ì¶œ ë° JSON ë³€í™˜
"""

import pandas as pd
import json
import numpy as np
from pathlib import Path

# ì„¤ì •
CSV_FILE = "../../../../fenomeno_projects/Global_Scouter/Global_Scouter_20251003/A_Company.csv"
OUTPUT_DIR = "./data"

def extract_correct_data():
    """ì˜¬ë°”ë¥¸ í˜•íƒœë¡œ CSV ë°ì´í„° ì¶”ì¶œ"""
    print("ğŸ” CSV íŒŒì¼ êµ¬ì¡° ë¶„ì„ ì¤‘...")
    
    # CSV íŒŒì¼ ì½ê¸°
    df_raw = pd.read_csv(CSV_FILE, encoding='utf-8')
    print(f"ì›ë³¸ íŒŒì¼ í¬ê¸°: {df_raw.shape}")
    
    # ì‹¤ì œ í—¤ë”ëŠ” 1ë²ˆì§¸ í–‰ (ì¸ë±ìŠ¤ 1)
    headers = df_raw.iloc[1].tolist()
    print(f"í—¤ë” ê°œìˆ˜: {len(headers)}")
    print(f"ì²« 10ê°œ í—¤ë”: {headers[1:11]}")  # ì²« ë²ˆì§¸ëŠ” ë¹ˆ ì»¬ëŸ¼
    
    # ë°ì´í„°ëŠ” 2ë²ˆì§¸ í–‰ë¶€í„° (ì¸ë±ìŠ¤ 2ë¶€í„°)
    data_rows = df_raw.iloc[2:].copy()
    
    # í—¤ë” ì„¤ì • (ì²« ë²ˆì§¸ ë¹ˆ ì»¬ëŸ¼ ì œì™¸)
    valid_headers = headers[1:]  # ì²« ë²ˆì§¸ ë¹ˆ ì»¬ëŸ¼ ì œê±°
    data_rows.columns = range(len(data_rows.columns))  # ì„ì‹œ ì»¬ëŸ¼ëª…
    data_rows = data_rows.iloc[:, 1:]  # ì²« ë²ˆì§¸ ë¹ˆ ì»¬ëŸ¼ ì œê±°
    data_rows.columns = valid_headers[:len(data_rows.columns)]  # ì˜¬ë°”ë¥¸ í—¤ë” ì ìš©
    
    print(f"ì •ì œëœ ë°ì´í„° í¬ê¸°: {data_rows.shape}")
    print(f"ì»¬ëŸ¼ëª…: {list(data_rows.columns[:10])}")
    
    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
    print("\\nğŸ“Š ìƒ˜í”Œ ë°ì´í„°:")
    for i in range(min(3, len(data_rows))):
        row = data_rows.iloc[i]
        print(f"  {i+1}. {row.iloc[0]} - {row.iloc[1]} ({row.iloc[2]})")
    
    return data_rows

def create_enhanced_json(df):
    """ê°•í™”ëœ JSON ë°ì´í„° ìƒì„±"""
    print("\\nğŸ”§ JSON ë°ì´í„° ìƒì„± ì¤‘...")
    
    # ê¸°ë³¸ ì •ë³´ ë§¤í•‘
    column_mapping = {
        'Ticker': 'Ticker',
        'Corp': 'corpName', 
        'Exchange': 'exchange',
        'WI26': 'industry'  # ì‹¤ì œ ì»¬ëŸ¼ëª… í™•ì¸ í•„ìš”
    }
    
    enhanced_data = []
    
    for idx, row in df.iterrows():
        if pd.isna(row.iloc[0]) or row.iloc[0] == '':  # ë¹ˆ í–‰ ìŠ¤í‚µ
            continue
            
        company = {
            'Ticker': str(row.iloc[0]) if pd.notna(row.iloc[0]) else '',
            'corpName': str(row.iloc[1]) if pd.notna(row.iloc[1]) else '',
            'exchange': str(row.iloc[2]) if pd.notna(row.iloc[2]) else '',
            'industry': str(row.iloc[3]) if pd.notna(row.iloc[3]) else ''
        }
        
        # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ë“¤ì„ ìˆ«ì ë°ì´í„°ë¡œ ì²˜ë¦¬
        for i, col_name in enumerate(df.columns[4:], 4):
            value = row.iloc[i]
            if pd.isna(value) or value == '' or value == 'N/A':
                company[col_name] = None
            else:
                try:
                    num_value = float(value)
                    # NaN, Infinity ì²´í¬
                    if np.isnan(num_value) or np.isinf(num_value):
                        company[col_name] = None
                    else:
                        company[col_name] = num_value
                except (ValueError, TypeError):
                    company[col_name] = str(value) if str(value) != 'nan' else None
        
        # ê²€ìƒ‰ ì¸ë±ìŠ¤ ì¶”ê°€
        company['searchIndex'] = f"{company['Ticker']} {company['corpName']}".lower()
        
        enhanced_data.append(company)
    
    print(f"âœ… {len(enhanced_data)}ê°œ ê¸°ì—… ë°ì´í„° ìƒì„±")
    return enhanced_data

def save_data(data):
    """ë°ì´í„° ì €ì¥"""
    print("\\nğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘...")
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    Path(OUTPUT_DIR).mkdir(exist_ok=True)
    
    # ë©”íƒ€ë°ì´í„° ìƒì„±
    metadata = {
        'version': '2.0',
        'generated_at': pd.Timestamp.now().isoformat(),
        'total_companies': len(data),
        'description': 'Global_Scouter ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ'
    }
    
    # ìµœì¢… ë°ì´í„° êµ¬ì¡°
    final_data = {
        'metadata': metadata,
        'companies': data
    }
    
    # JSON íŒŒì¼ ì €ì¥
    output_file = f"{OUTPUT_DIR}/enhanced_summary_data.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2, default=str)
    
    # íŒŒì¼ í¬ê¸° í™•ì¸
    file_size = Path(output_file).stat().st_size
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_file}")
    print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size/1024/1024:.1f}MB")
    
    # ì»¬ëŸ¼ ì„¤ì • íŒŒì¼ë„ ìƒì„±
    create_column_config(data[0] if data else {})
    
    return final_data

def create_column_config(sample_company):
    """ì»¬ëŸ¼ ì„¤ì • íŒŒì¼ ìƒì„±"""
    config = {
        'categories': {
            'basic': {
                'name': 'ê¸°ë³¸ì •ë³´',
                'columns': ['Ticker', 'corpName', 'exchange', 'industry']
            }
        },
        'korean_names': {
            'Ticker': 'í‹°ì»¤',
            'corpName': 'íšŒì‚¬ëª…',
            'exchange': 'ê±°ë˜ì†Œ',
            'industry': 'ì—…ì¢…'
        },
        'available_columns': list(sample_company.keys()) if sample_company else []
    }
    
    config_file = f"{OUTPUT_DIR}/column_config.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ì»¬ëŸ¼ ì„¤ì • ì €ì¥: {config_file}")

def main():
    print("ğŸš€ ì˜¬ë°”ë¥¸ ë°ì´í„° ì¶”ì¶œ ì‹œì‘")
    print("=" * 50)
    
    # 1. ë°ì´í„° ì¶”ì¶œ
    df = extract_correct_data()
    
    # 2. JSON ë³€í™˜
    enhanced_data = create_enhanced_json(df)
    
    # 3. ì €ì¥
    final_data = save_data(enhanced_data)
    
    print("\\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ {len(enhanced_data)}ê°œ ê¸°ì—…")
    print("\\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ í…ŒìŠ¤íŠ¸")
    print("   2. ë°ì´í„° êµ¬ì¡° í™•ì¸")

if __name__ == "__main__":
    main()