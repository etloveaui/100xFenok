#!/usr/bin/env python3
"""
Global_Scouter CSV íŒŒì¼ êµ¬ì¡° ë¶„ì„ ë„êµ¬
22ê°œ CSV íŒŒì¼ì˜ êµ¬ì¡°, ì»¬ëŸ¼, ë°ì´í„° íƒ€ì…ì„ ë¶„ì„í•˜ì—¬ 
ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ë°ì´í„° êµ¬ì¡°ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
"""

import pandas as pd
import os
import json
from pathlib import Path

# Global_Scouter CSV íŒŒì¼ ê²½ë¡œ
CSV_DIR = Path(r"C:\Users\etlov\agents-workspace\fenomeno_projects\Global_Scouter\Global_Scouter_20251003")

def analyze_csv_files():
    """ëª¨ë“  CSV íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ êµ¬ì¡° ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    analysis_results = {}
    
    # CSV íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    print(f"ğŸ” CSV ë””ë ‰í† ë¦¬ ê²½ë¡œ: {CSV_DIR}")
    print(f"ğŸ” ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€: {CSV_DIR.exists()}")
    
    if CSV_DIR.exists():
        csv_files = list(CSV_DIR.glob("*.csv"))
        print(f"ğŸ” ì°¾ì€ íŒŒì¼ë“¤: {[f.name for f in csv_files]}")
    else:
        csv_files = []
    
    print(f"ğŸ“Š ì´ {len(csv_files)}ê°œ CSV íŒŒì¼ ë¶„ì„ ì‹œì‘...")
    print("=" * 60)
    
    for csv_file in csv_files:
        print(f"\nğŸ” ë¶„ì„ ì¤‘: {csv_file.name}")
        
        try:
            # CSV íŒŒì¼ ì½ê¸° (ë‹¤ì¤‘ í—¤ë” êµ¬ì¡° ì²˜ë¦¬)
            try:
                # ë¨¼ì € í—¤ë” êµ¬ì¡° íŒŒì•…
                header_df = pd.read_csv(csv_file, encoding='utf-8', nrows=5)
                
                # ì‹¤ì œ ë°ì´í„°ëŠ” 3í–‰ë¶€í„° ì‹œì‘ (0-based indexë¡œ 2)
                df = pd.read_csv(csv_file, encoding='utf-8', header=[2])
                
                # í—¤ë” ì •ë³´ë„ ì €ì¥
                if len(header_df) >= 3:
                    category_headers = header_df.iloc[1].fillna('').tolist()
                    column_headers = header_df.iloc[2].fillna('').tolist()
                else:
                    category_headers = []
                    column_headers = list(df.columns)
                    
            except UnicodeDecodeError:
                df = pd.read_csv(csv_file, encoding='cp949', header=[2])
                category_headers = []
                column_headers = list(df.columns)
            except Exception as e:
                print(f"   âš ï¸  í—¤ë” íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©: {e}")
                df = pd.read_csv(csv_file, encoding='utf-8')
                category_headers = []
                column_headers = list(df.columns)
            
            # ê¸°ë³¸ ì •ë³´
            file_info = {
                'filename': csv_file.name,
                'rows': len(df),
                'columns': len(df.columns),
                'column_names': column_headers,
                'category_headers': category_headers,
                'data_types': df.dtypes.astype(str).to_dict(),
                'sample_data': {},
                'key_columns': [],
                'numeric_columns': [],
                'categorical_columns': [],
                'financial_indicators': []
            }
            
            # ìƒ˜í”Œ ë°ì´í„° (ì²« 3í–‰)
            for col in df.columns[:10]:  # ì²˜ìŒ 10ê°œ ì»¬ëŸ¼ë§Œ
                sample_values = df[col].head(3).fillna('NULL').tolist()
                file_info['sample_data'][col] = sample_values
            
            # ì»¬ëŸ¼ ë¶„ë¥˜ (ì‹¤ì œ ì»¬ëŸ¼ëª… ì‚¬ìš©)
            for i, col in enumerate(column_headers):
                col_lower = str(col).lower()
                
                # í‚¤ ì»¬ëŸ¼ ì‹ë³„
                if any(keyword in col_lower for keyword in ['ticker', 'corp', 'symbol', 'company']):
                    file_info['key_columns'].append(col)
                
                # ë°ì´í„° íƒ€ì…ë³„ ë¶„ë¥˜
                if i < len(df.columns):
                    if df.iloc[:, i].dtype in ['int64', 'float64']:
                        file_info['numeric_columns'].append(col)
                    elif df.iloc[:, i].dtype == 'object':
                        file_info['categorical_columns'].append(col)
            
            # ê¸ˆìœµ ì§€í‘œ ì‹ë³„ (ë” í¬ê´„ì ìœ¼ë¡œ)
            financial_indicators = []
            for col in column_headers:
                col_str = str(col).lower()
                if any(keyword in col_str for keyword in 
                      ['per', 'pbr', 'roe', 'roa', 'eps', 'sales', 'growth', 
                       'margin', 'ratio', 'return', 'yield', 'cap', 'price',
                       'opm', 'ccc', 'peg', 'bps', 'dy', 'ytd']):
                    financial_indicators.append(col)
            
            file_info['financial_indicators'] = financial_indicators
            
            analysis_results[csv_file.name] = file_info
            
            # ê°„ë‹¨í•œ ìš”ì•½ ì¶œë ¥
            print(f"   ğŸ“ í¬ê¸°: {len(df)} í–‰ Ã— {len(df.columns)} ì—´")
            print(f"   ğŸ”‘ ì£¼ìš” ì»¬ëŸ¼: {file_info['key_columns']}")
            print(f"   ğŸ“ˆ ê¸ˆìœµì§€í‘œ: {len(financial_indicators)}ê°œ")
            
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {str(e)}")
            analysis_results[csv_file.name] = {'error': str(e)}
    
    return analysis_results

def identify_key_files(analysis_results):
    """í•µì‹¬ íŒŒì¼ë“¤ì„ ì‹ë³„í•©ë‹ˆë‹¤."""
    
    print("\n" + "=" * 60)
    print("ğŸ¯ í•µì‹¬ íŒŒì¼ ì‹ë³„")
    print("=" * 60)
    
    key_files = {}
    
    for filename, info in analysis_results.items():
        if 'error' in info:
            continue
            
        # íŒŒì¼ ì¤‘ìš”ë„ í‰ê°€
        importance_score = 0
        
        # ê¸°ì—… ì •ë³´ê°€ ìˆëŠ” íŒŒì¼
        if any('ticker' in col.lower() or 'corp' in col.lower() 
               for col in info.get('column_names', [])):
            importance_score += 10
        
        # ê¸ˆìœµ ì§€í‘œê°€ ë§ì€ íŒŒì¼
        importance_score += len(info.get('financial_indicators', []))
        
        # ë°ì´í„°ê°€ ë§ì€ íŒŒì¼
        if info.get('rows', 0) > 100:
            importance_score += 5
        
        key_files[filename] = {
            'importance_score': importance_score,
            'rows': info.get('rows', 0),
            'financial_indicators': len(info.get('financial_indicators', [])),
            'description': get_file_description(filename)
        }
    
    # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_files = sorted(key_files.items(), 
                         key=lambda x: x[1]['importance_score'], 
                         reverse=True)
    
    print("\nğŸ“Š íŒŒì¼ ì¤‘ìš”ë„ ìˆœìœ„:")
    for i, (filename, info) in enumerate(sorted_files[:10], 1):
        print(f"{i:2d}. {filename}")
        print(f"    ì ìˆ˜: {info['importance_score']}, "
              f"í–‰ìˆ˜: {info['rows']}, "
              f"ì§€í‘œìˆ˜: {info['financial_indicators']}")
        print(f"    ì„¤ëª…: {info['description']}")
        print()
    
    return sorted_files

def get_file_description(filename):
    """íŒŒì¼ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    descriptions = {
        'A_Company.csv': 'ê¸°ì—… ê¸°ë³¸ì •ë³´ ë° í•µì‹¬ ì§€í‘œ',
        'A_Compare.csv': 'ë™ì¢…ì—…ê³„ ë¹„êµ ë¶„ì„',
        'A_Contrast.csv': 'ëŒ€ì¡° ë¶„ì„ ë°ì´í„°',
        'A_Distribution.csv': 'ë¶„ë°° ê´€ë ¨ ë°ì´í„°',
        'A_ETFs.csv': 'ETF ê´€ë ¨ ì •ë³´',
        'T_Rank.csv': 'ê°ì¢… ì§€í‘œë³„ ìˆœìœ„',
        'T_Growth_C.csv': 'ì„±ì¥ë¥  ì»¨ì„¼ì„œìŠ¤',
        'T_Growth_H.csv': 'ì„±ì¥ë¥  íˆìŠ¤í† ë¦¬',
        'T_EPS_C.csv': 'EPS ì»¨ì„¼ì„œìŠ¤',
        'T_EPS_H.csv': 'EPS íˆìŠ¤í† ë¦¬',
        'S_Valuation.csv': 'ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„',
        'S_Chart.csv': 'ì°¨íŠ¸ ë°ì´í„°',
        'S_Mylist.csv': 'ì‚¬ìš©ì ê´€ì‹¬ ì¢…ëª©',
        'T_CFO.csv': 'CFO ê´€ë ¨ ì§€í‘œ',
        'T_Chart.csv': 'ê¸°ìˆ ì  ë¶„ì„ ë°ì´í„°',
        'T_Chk.csv': 'ì²´í¬ë¦¬ìŠ¤íŠ¸ ë°ì´í„°',
        'T_Correlation.csv': 'ìƒê´€ê´€ê³„ ë¶„ì„',
        'M_Company.csv': 'ì›”ê°„ ê¸°ì—… ë°ì´í„°',
        'M_ETFs.csv': 'ì›”ê°„ ETF ë°ì´í„°',
        'E_Indicators.csv': 'ê²½ì œ ì§€í‘œ',
        'UP_&_Down.csv': 'ìƒìŠ¹/í•˜ë½ ë¶„ì„',
        'ReadMe.csv': 'ì„¤ëª…ì„œ'
    }
    
    return descriptions.get(filename, 'ê¸°íƒ€ ë°ì´í„°')

def generate_data_strategy(analysis_results, key_files):
    """ë°ì´í„° í™œìš© ì „ëµì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    print("\n" + "=" * 60)
    print("ğŸš€ ë°ì´í„° í™œìš© ì „ëµ")
    print("=" * 60)
    
    strategy = {
        'primary_files': [],      # í•µì‹¬ íŒŒì¼ë“¤
        'secondary_files': [],    # ë³´ì¡° íŒŒì¼ë“¤
        'web_columns': [],        # ì›¹ì—ì„œ í‘œì‹œí•  ì»¬ëŸ¼ë“¤
        'filter_columns': [],     # í•„í„°ë§ìš© ì»¬ëŸ¼ë“¤
        'sort_columns': [],       # ì •ë ¬ìš© ì»¬ëŸ¼ë“¤
        'chart_columns': []       # ì°¨íŠ¸ìš© ì»¬ëŸ¼ë“¤
    }
    
    # ìƒìœ„ 5ê°œ íŒŒì¼ì„ í•µì‹¬ íŒŒì¼ë¡œ ì„ ì •
    for filename, info in key_files[:5]:
        strategy['primary_files'].append({
            'filename': filename,
            'description': info['description'],
            'usage': get_usage_recommendation(filename)
        })
    
    # A_Company.csv ìƒì„¸ ë¶„ì„ (ê°€ì¥ ì¤‘ìš”í•œ íŒŒì¼)
    if 'A_Company.csv' in analysis_results:
        company_info = analysis_results['A_Company.csv']
        
        print("\nğŸ“‹ A_Company.csv ìƒì„¸ ë¶„ì„:")
        print(f"   ì´ {company_info['rows']}ê°œ ê¸°ì—…")
        print(f"   ì´ {company_info['columns']}ê°œ ì»¬ëŸ¼")
        
        # ì›¹ì—ì„œ í‘œì‹œí•  í•µì‹¬ ì»¬ëŸ¼ë“¤ ì¶”ì²œ
        recommended_columns = []
        for col in company_info['column_names']:
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in 
                  ['ticker', 'corp', 'exchange', 'industry', 'market', 
                   'roe', 'per', 'pbr', 'sales', 'growth', 'price']):
                recommended_columns.append(col)
        
        strategy['web_columns'] = recommended_columns[:15]  # ìƒìœ„ 15ê°œ
        
        print(f"   ğŸŒ ì›¹ í‘œì‹œ ì¶”ì²œ ì»¬ëŸ¼ ({len(strategy['web_columns'])}ê°œ):")
        for col in strategy['web_columns']:
            print(f"      - {col}")
    
    return strategy

def get_usage_recommendation(filename):
    """íŒŒì¼ë³„ ì‚¬ìš© ìš©ë„ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤."""
    
    usage_map = {
        'A_Company.csv': 'ë©”ì¸ í…Œì´ë¸” - ê¸°ì—… ëª©ë¡ ë° í•µì‹¬ ì§€í‘œ í‘œì‹œ',
        'T_Rank.csv': 'ë­í‚¹ ì‹œìŠ¤í…œ - ê° ì§€í‘œë³„ ìƒìœ„ ì¢…ëª© í‘œì‹œ',
        'S_Valuation.csv': 'ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„ - ì ì •ê°€ê²© vs í˜„ì¬ê°€ ë¹„êµ',
        'A_Compare.csv': 'ì„¹í„° ë¹„êµ - ë™ì¢…ì—…ê³„ ë²¤ì¹˜ë§ˆí‚¹',
        'T_Growth_C.csv': 'ì„±ì¥ë¥  ë¶„ì„ - ë¯¸ë˜ ì„±ì¥ ì „ë§'
    }
    
    return usage_map.get(filename, 'ì¶”ê°€ ë¶„ì„ìš© ë°ì´í„°')

def save_analysis_results(analysis_results, strategy):
    """ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    
    output_file = "csv_analysis_results.json"
    
    output_data = {
        'analysis_date': pd.Timestamp.now().isoformat(),
        'total_files': len(analysis_results),
        'file_analysis': analysis_results,
        'data_strategy': strategy
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_file}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ” Global_Scouter CSV êµ¬ì¡° ë¶„ì„ ë„êµ¬")
    print("=" * 60)
    
    # CSV íŒŒì¼ë“¤ ë¶„ì„
    analysis_results = analyze_csv_files()
    
    # í•µì‹¬ íŒŒì¼ë“¤ ì‹ë³„
    key_files = identify_key_files(analysis_results)
    
    # ë°ì´í„° í™œìš© ì „ëµ ìƒì„±
    strategy = generate_data_strategy(analysis_results, key_files)
    
    # ê²°ê³¼ ì €ì¥
    save_analysis_results(analysis_results, strategy)
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")
    print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
    print("1. csv_analysis_results.json íŒŒì¼ ê²€í† ")
    print("2. í•µì‹¬ íŒŒì¼ë“¤ì˜ ë°ì´í„° í†µí•© ê³„íš ìˆ˜ë¦½")
    print("3. ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¬ëŸ¼ êµ¬ì¡° ì„¤ê³„")

if __name__ == "__main__":
    main()