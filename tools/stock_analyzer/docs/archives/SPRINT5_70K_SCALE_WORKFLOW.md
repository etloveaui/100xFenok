# Sprint 5 - 70,000 ê¸°ì—… ìŠ¤ì¼€ì¼ ì—…ê·¸ë ˆì´ë“œ ì›Œí¬í”Œë¡œìš°

**ì‘ì„±ì¼**: 2025-10-18
**ë°©ë²•ë¡ **: fenomeno-auto-v9 + SPEC_DRIVEN_WORKFLOW
**ëª©í‘œ**: CorrelationEngine 70,000ê°œ ê¸°ì—… ëŒ€ì‘ ì•„í‚¤í…ì²˜ êµ¬ì¶•

---

## ğŸ“‹ ì‘ì—… ì„œë‘ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ë§¤ ì‘ì—… ì „ í™•ì¸)

```yaml
âœ… ê³„íšì„œ ì‘ì„±: ì´ ë¬¸ì„œ (SPRINT5_70K_SCALE_WORKFLOW.md)
âœ… SC ëª…ë ¹: /sc:workflow â†’ /sc:implement â†’ /sc:test
âœ… ëª¨ë“œ: fenomeno-auto-v9 (ë³‘ë ¬ ìš°ì„ , ì¦‰ì‹œ ì‹¤í–‰)
âœ… MCP ì„œë²„: Sequential (ë¶„ì„), Serena (ë©”ëª¨ë¦¬), Playwright (í…ŒìŠ¤íŠ¸)
âœ… ì„œë¸Œ ì—ì´ì „íŠ¸: @performance-engineer, @system-architect, @quality-engineer
âœ… ë¬¸ì„œ ì‘ì—…: claudedocs ë””ë ‰í† ë¦¬ì— ëª¨ë“  ê²°ê³¼ë¬¼ ì €ì¥
âœ… ì‹¤í–‰: ê³„íš ìŠ¹ì¸ í›„ ë‹¨ê³„ë³„ ì§„í–‰
```

---

## ğŸ¯ í•µì‹¬ ëª©í‘œ ë° ìŠ¤ì¼€ì¼ ìš”êµ¬ì‚¬í•­

### í˜„ì¬ ìƒíƒœ
- **ë°ì´í„°**: M_Company.csv 6,178ê°œ ê¸°ì—…
- **í˜„ì¬ ì‹œìŠ¤í…œ**: 1,264ê°œ ê¸°ì—…ìœ¼ë¡œ ì œí•œ
- **ì•Œê³ ë¦¬ì¦˜**: O(nÂ²) ë³µì¡ë„ë¡œ 1,249ê°œì—ì„œ ì„±ëŠ¥ ì €í•˜

### ëª©í‘œ ìƒíƒœ
- **ìµœì†Œ ìŠ¤ì¼€ì¼**: 6,000ê°œ ê¸°ì—… ì²˜ë¦¬
- **ê¶Œì¥ ìŠ¤ì¼€ì¼**: 10,000ê°œ ê¸°ì—… ì²˜ë¦¬
- **ìµœëŒ€ ìŠ¤ì¼€ì¼**: **70,000ê°œ ê¸°ì—… ì²˜ë¦¬** (í™•ì¥ ê°€ëŠ¥ ì•„í‚¤í…ì²˜)
- **ì„±ëŠ¥ ëª©í‘œ**:
  - ì´ˆê¸°í™” < 3ì´ˆ
  - Correlation matrix ê³„ì‚° < 5ì´ˆ
  - findLowCorrelationPairs() < 2ì´ˆ
  - ì „ì²´ í…ŒìŠ¤íŠ¸ í†µê³¼ (93ê°œ í…ŒìŠ¤íŠ¸)

---

## ğŸš€ 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° (SPEC_DRIVEN_WORKFLOW)

### Phase 0: As-Is ë¶„ì„ (Complete)
**Status**: âœ… ì™„ë£Œë¨

**ë°œê²¬ì‚¬í•­**:
1. **ë°ì´í„° ë¶ˆì¼ì¹˜**:
   - M_Company.csv: 6,178ê°œ âœ…
   - T_CFO.csv: 1,267ê°œ âŒ
   - T_Correlation.csv: 1,252ê°œ âŒ
   - global_scouter_integrated.json: 1,264ê°œ âŒ

2. **ì„±ëŠ¥ ë³‘ëª©**:
   - `CorrelationEngine.js:171` findLowCorrelationPairs() O(nÂ²)
   - 1,249ê°œ: ~779,376 ìŒ ê³„ì‚°
   - 6,000ê°œ: ~18,000,000 ìŒ (23ë°°)
   - 70,000ê°œ: ~2,449,965,000 ìŒ (3,145ë°°!)

3. **í…ŒìŠ¤íŠ¸ ê²°ê³¼**:
   - CorrelationEngine ë‹¨ì¼: 18/19 âœ… (94.7%)
   - ì „ì²´ í…ŒìŠ¤íŠ¸: 25/93 âŒ (26.9%)
   - ì£¼ìš” ì‹¤íŒ¨: test #26 findLowCorrelationPairs() ë¬´í•œ ëŒ€ê¸°

**ê·¼ë³¸ ì›ì¸**:
- CSV íŒŒì´í”„ë¼ì¸ ë¯¸ì‹¤í–‰ â†’ ë°ì´í„° 1,264ê°œë¡œ ì œí•œ
- O(nÂ²) ì•Œê³ ë¦¬ì¦˜ â†’ ìŠ¤ì¼€ì¼ ë¶ˆê°€ëŠ¥
- í…ŒìŠ¤íŠ¸ íƒ€ì„ì•„ì›ƒ ë¶€ì¡± â†’ ë°ì´í„° ê°ì†Œë¡œ ì˜ëª» í•´ê²° ì‹œë„

---

### Phase 1: To-Be ì„¤ê³„ (Current)

#### 1.1 ë°ì´í„° ì•„í‚¤í…ì²˜
```yaml
data_pipeline:
  source: fenomeno_projects/Global_Scouter/Global_Scouter_20251003/*.csv
  conversion: scripts/csv_pipeline.sh
  target: data/global_scouter_integrated.json
  expected_companies: 6,178ê°œ (ì´ˆê¸°)
  max_capacity: 70,000ê°œ (ì„¤ê³„)

data_structure:
  M_Company: ê¸°ì—… ê¸°ë³¸ ì •ë³´ (6,178ê°œ)
  T_CFO: í˜„ê¸ˆíë¦„ ë°ì´í„° (1,267ê°œ â†’ 6,178ê°œ)
  T_Correlation: ìƒê´€ê³„ìˆ˜ ë°ì´í„° (1,252ê°œ â†’ 6,178ê°œ)
  T_Growth_C: ì„±ì¥ë¥  ë°ì´í„°
  T_EPS_C: EPS ë°ì´í„°
```

#### 1.2 ì•Œê³ ë¦¬ì¦˜ ìµœì í™” ì„¤ê³„
```javascript
// âŒ í˜„ì¬: O(nÂ²) - 70,000ê°œ ë¶ˆê°€ëŠ¥
findLowCorrelationPairs(minCorr, maxCorr, tickerSubset) {
  for (let i = 0; i < n; i++) {
    for (let j = i + 1; j < n; j++) {
      // 2,449,965,000 iterations for 70,000!
    }
  }
}

// âœ… ìµœì í™” 1: Pre-computed Matrix + Index (O(nÂ²) â†’ O(n))
class CorrelationEngine {
  constructor() {
    this.correlationMatrix = new Map(); // Ticker â†’ Map<Ticker, Correlation>
    this.correlationIndex = {
      low: [],    // corr < -0.3
      medium: [], // -0.3 <= corr <= 0.3
      high: []    // corr > 0.3
    };
  }

  buildCorrelationMatrix() {
    // O(nÂ²) once at initialization
    // Store in indexed structure
  }

  findLowCorrelationPairs(minCorr, maxCorr, tickerSubset) {
    // O(n) lookup from pre-indexed structure
    return this.correlationIndex.medium.filter(...);
  }
}

// âœ… ìµœì í™” 2: Web Workers (ë³‘ë ¬ ê³„ì‚°)
class CorrelationEngine {
  async buildCorrelationMatrixParallel() {
    const workers = navigator.hardwareConcurrency || 4;
    const chunkSize = Math.ceil(n / workers);
    // Split nÃ—n matrix into 4 chunks, calculate in parallel
    // 70,000Â²/4 = 612M iterations per worker
  }
}

// âœ… ìµœì í™” 3: Sparse Matrix (ë©”ëª¨ë¦¬ ìµœì í™”)
class SparseCorrelationMatrix {
  constructor() {
    this.data = new Map(); // Only store non-zero correlations
    this.threshold = 0.01; // Ignore correlations < 0.01
  }

  // 70,000Â² = 4.9GB (full) â†’ ~500MB (sparse, 10% density)
}
```

#### 1.3 ì„±ëŠ¥ ëª©í‘œ (70,000ê°œ ê¸°ì—…)
```yaml
initialization:
  target: < 5ì´ˆ
  current: ~2ì´ˆ (1,264ê°œ)
  scaling: 70,000/1,264 = 55ë°° â†’ 110ì´ˆ ì˜ˆìƒ
  optimization: Web Workers 4ê°œ â†’ 27ì´ˆ ëª©í‘œ

correlation_matrix:
  target: < 10ì´ˆ
  complexity: O(nÂ²) â†’ 4.9B calculations
  optimization:
    - Sparse matrix (10% density) â†’ 490M calculations
    - Web Workers 4ê°œ â†’ 120M per worker
    - Estimated: 8ì´ˆ

query_performance:
  findLowCorrelationPairs: < 2ì´ˆ (indexed lookup O(n))
  buildDiversifiedPortfolio: < 3ì´ˆ
  clusterByCorrelation: < 5ì´ˆ (k-means with sampling)

memory_usage:
  target: < 2GB
  breakdown:
    - Sparse matrix: ~500MB
    - Company data: ~200MB
    - Chart data: ~100MB
    - Browser overhead: ~500MB
```

---

### Phase 2: Master Plan (Implementation Steps)

#### Step 1: ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ [checkpoint-004]
**Owner**: CSV ì»¨ë²„í„°
**Duration**: 5ë¶„
**Agent**: filesystem MCP + python

**Task**:
1. CSV íŒŒì¼ ë³µì‚¬: `Global_Scouter_20251003/*.csv` â†’ `data/csv/`
2. Pipeline ì‹¤í–‰: `bash scripts/csv_pipeline.sh`
3. ê²€ì¦: `global_scouter_integrated.json` 6,178ê°œ í™•ì¸

**Success Criteria**:
- [ ] M_Company 6,178ê°œ
- [ ] T_CFO 6,178ê°œ
- [ ] T_Correlation 6,178ê°œ
- [ ] JSON íŒŒì¼ í¬ê¸° > 50MB

---

#### Step 2: CorrelationEngine ì•Œê³ ë¦¬ì¦˜ ìµœì í™” [checkpoint-005]
**Owner**: @performance-engineer + @system-architect
**Duration**: 20ë¶„
**Agent**: Task (ë³‘ë ¬), Sequential MCP

**Sub-tasks**:
1. **Indexed Structure** (8ë¶„)
   - Pre-computed correlation matrix with Map
   - Build low/medium/high correlation indices
   - Update `buildCorrelationMatrix()` method

2. **Sparse Matrix** (6ë¶„)
   - Implement SparseCorrelationMatrix class
   - Threshold-based storage (correlations > 0.01)
   - Memory profiling

3. **Query Optimization** (6ë¶„)
   - Refactor `findLowCorrelationPairs()` for O(n) lookup
   - Update `buildDiversifiedPortfolio()` with sampling
   - Optimize `clusterByCorrelation()` with k-means++

**Files Modified**:
- `modules/CorrelationEngine.js` (lines 80-250)
- NEW: `modules/SparseMatrix.js`
- NEW: `modules/PerformanceMonitor.js`

**Success Criteria**:
- [ ] 6,000ê°œ: Correlation matrix < 5ì´ˆ
- [ ] findLowCorrelationPairs() < 2ì´ˆ
- [ ] Memory usage < 1GB

---

#### Step 3: í…ŒìŠ¤íŠ¸ ìŠ¤í™ ì—…ë°ì´íŠ¸ [checkpoint-006]
**Owner**: @quality-engineer
**Duration**: 10ë¶„
**Agent**: Edit tool

**Sub-tasks**:
1. **Revert Data Reduction** (3ë¶„)
   - `tests/sprint5-correlation-engine.spec.js:171-176`
   - Remove `.slice(0, 50)` hack
   - Restore full dataset tests

2. **Update Timeouts** (3ë¶„)
   - Test #26 findLowCorrelationPairs: 60s â†’ 120s
   - Performance tests: Adjust thresholds for 6,000 companies

3. **Add Scale Tests** (4ë¶„)
   - NEW: test "handles 6,000 companies efficiently"
   - NEW: test "memory usage < 2GB with 6,000 companies"

**Files Modified**:
- `tests/sprint5-correlation-engine.spec.js`
- `tests/sprint5-performance.spec.js`
- `playwright.config.ts` (global timeout)

---

#### Step 4: ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²€ì¦ [checkpoint-007]
**Owner**: @quality-engineer
**Duration**: 15ë¶„
**Agent**: Playwright MCP

**Execution**:
```bash
cd projects/100xFenok/tools/stock_analyzer
npx playwright test tests/sprint5-*.spec.js --project=chromium --reporter=list --workers=1
```

**Success Criteria**:
- [ ] 93/93 í…ŒìŠ¤íŠ¸ í†µê³¼ (100%)
- [ ] ì „ì²´ ì‹¤í–‰ ì‹œê°„ < 10ë¶„
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ < 2GB
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ëª¨ë‘ í†µê³¼

---

#### Step 5: ë¬¸ì„œí™” ë° ìµœì¢… ë³´ê³  [checkpoint-008]
**Owner**: @technical-writer
**Duration**: 10ë¶„

**Deliverables**:
1. `SPRINT5_70K_IMPLEMENTATION.md` (êµ¬í˜„ ìƒì„¸)
2. `SPRINT5_PERFORMANCE_REPORT.md` (ì„±ëŠ¥ ë¶„ì„)
3. `SPRINT5_FINAL_SUMMARY.md` (ìµœì¢… ìš”ì•½)
4. Git commit with detailed message

---

### Phase 3: ì‹¤í–‰ ì „ëµ (fenomeno-auto-v9)

#### ë³‘ë ¬ ì‹¤í–‰ ë§¤íŠ¸ë¦­ìŠ¤
```yaml
parallel_group_1: # ë…ë¦½ ì‘ì—… (Step 1)
  - task: CSV íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    duration: 5ë¶„
    agent: filesystem MCP

parallel_group_2: # Step 2 ì„œë¸ŒíƒœìŠ¤í¬ (ë³‘ë ¬ ê°€ëŠ¥)
  - task_2a: Indexed Structure
    agent: @performance-engineer
  - task_2b: Sparse Matrix
    agent: @system-architect
  # ë³‘ë ¬ ì‹¤í–‰ â†’ 8ë¶„ (ìˆœì°¨: 14ë¶„)

sequential_group: # ì˜ì¡´ì„± ìˆëŠ” ì‘ì—…
  - step_1 â†’ step_2 (ë°ì´í„° í•„ìš”)
  - step_2 â†’ step_3 (ì•Œê³ ë¦¬ì¦˜ ì™„ë£Œ í›„ í…ŒìŠ¤íŠ¸)
  - step_3 â†’ step_4 (í…ŒìŠ¤íŠ¸ ìŠ¤í™ ì—…ë°ì´íŠ¸ í›„ ì‹¤í–‰)
```

#### ì—ì´ì „íŠ¸ íˆ¬ì… ì „ëµ
```yaml
phase_1_data: # Step 1
  agents: []
  tools: [Bash, Read, Write]
  mcp: [filesystem]

phase_2_optimization: # Step 2
  agents:
    - type: performance-engineer
      task: ì•Œê³ ë¦¬ì¦˜ ìµœì í™” (O(nÂ²) â†’ O(n))
      tools: [Task, Edit]
    - type: system-architect
      task: Sparse Matrix ì•„í‚¤í…ì²˜ ì„¤ê³„
      tools: [Task, Write]
  mcp: [Sequential, Serena]
  parallel: true

phase_3_testing: # Step 3-4
  agents:
    - type: quality-engineer
      task: í…ŒìŠ¤íŠ¸ ìŠ¤í™ ì—…ë°ì´íŠ¸ ë° ì‹¤í–‰
      tools: [Edit, Bash]
  mcp: [Playwright]

phase_4_documentation: # Step 5
  agents:
    - type: technical-writer
      task: ë¬¸ì„œ ì‘ì„± ë° ì •ë¦¬
      tools: [Write]
  mcp: []
```

#### MCP ì„œë²„ í™œìš© ì „ëµ
```yaml
sequential_mcp:
  when: Step 2 (ì•Œê³ ë¦¬ì¦˜ ë¶„ì„)
  purpose: ë³µì¡í•œ ì„±ëŠ¥ ìµœì í™” ì „ëµ ìˆ˜ë¦½
  output: ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì˜ì‚¬ì½”ë“œ

serena_mcp:
  when: ì „ì²´ workflow
  purpose: ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ì €ì¥, ë³µêµ¬ ì§€ì›
  checkpoints: [checkpoint-004, 005, 006, 007, 008]

playwright_mcp:
  when: Step 4 (í…ŒìŠ¤íŠ¸ ì‹¤í–‰)
  purpose: 93ê°œ E2E í…ŒìŠ¤íŠ¸ ìë™í™”
  config: --workers=1, --timeout=120000

filesystem_mcp:
  when: Step 1 (CSV ë³€í™˜)
  purpose: ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ìµœì í™”
```

---

## ğŸ“Š ì˜ˆìƒ ì†Œìš” ì‹œê°„

```yaml
ì´ ì˜ˆìƒ ì‹œê°„: 60ë¶„
breakdown:
  - Step 1 (Data): 5ë¶„
  - Step 2 (Algorithm): 20ë¶„ (ë³‘ë ¬ ì‹œ 8+12ë¶„)
  - Step 3 (Test Spec): 10ë¶„
  - Step 4 (Test Run): 15ë¶„
  - Step 5 (Docs): 10ë¶„

ë³‘ë ¬ ìµœì í™” ì‹œ: 50ë¶„
ë¦¬ìŠ¤í¬ ë²„í¼: +20ë¶„ (ë””ë²„ê¹…, ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œ)
ìµœì¢… ì˜ˆìƒ: 70ë¶„
```

---

## ğŸ¯ ì œì•ˆ ë° ëŒ€ì•ˆ

### ìµœê³ ì˜ ì œì•ˆ (ê¶Œì¥)
**ì „ëµ**: Incremental Scaling + Indexed Structure
- Step 2ì—ì„œ Indexed Structure ë¨¼ì € êµ¬í˜„
- 6,000ê°œë¡œ í…ŒìŠ¤íŠ¸ ì„±ê³µ í›„ â†’ 10,000ê°œ â†’ 70,000ê°œ ì ì§„ì  í™•ì¥
- ê° ë‹¨ê³„ë§ˆë‹¤ ì„±ëŠ¥ ì¸¡ì • ë° ìµœì í™”

**ì´ìœ **:
- ë¦¬ìŠ¤í¬ ìµœì†Œí™” (ë‹¨ê³„ë³„ ê²€ì¦)
- ì„±ëŠ¥ ë³‘ëª© ì¡°ê¸° ë°œê²¬
- 70,000ê°œ ì‹¤ì œ ë°ì´í„° ì—†ì–´ë„ êµ¬ì¡° ê²€ì¦ ê°€ëŠ¥

### ëŒ€ì•ˆ 1: Immediate Full Scale
**ì „ëµ**: 70,000ê°œ ì•„í‚¤í…ì²˜ë¥¼ ì¦‰ì‹œ êµ¬í˜„
- Sparse Matrix + Web Workers ë™ì‹œ ì ìš©
- 6,178ê°œ ë°ì´í„°ë¡œë§Œ ê²€ì¦

**ì´ìœ **:
- ë¹ ë¥¸ êµ¬í˜„ (ì•Œê³ ë¦¬ì¦˜ í•œ ë²ˆì—)
- Over-engineering ë¦¬ìŠ¤í¬

### ëŒ€ì•ˆ 2: Database Migration
**ì „ëµ**: IndexedDB ë˜ëŠ” SQLiteë¡œ ë°ì´í„° ì´ì „
- ë¸Œë¼ìš°ì € ë©”ëª¨ë¦¬ ë¶€ë‹´ ê°ì†Œ
- SQL ì¿¼ë¦¬ë¡œ correlation ê³„ì‚°

**ì´ìœ **:
- ë©”ëª¨ë¦¬ ì œì•½ í•´ê²°
- í”„ë¡ íŠ¸ì—”ë“œ ë³µì¡ë„ ì¦ê°€, ì•„í‚¤í…ì²˜ ë³€ê²½ í¼

---

## ğŸ”’ ì•ˆì „ ì¥ì¹˜

### Checkpoint Strategy
```yaml
checkpoint-004: CSV ë³€í™˜ ì™„ë£Œ
  - ë°ì´í„° 6,178ê°œ í™•ì¸
  - Git commit: "data: CSV íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ"

checkpoint-005: ì•Œê³ ë¦¬ì¦˜ ìµœì í™” ì™„ë£Œ
  - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
  - Git commit: "perf: CorrelationEngine 70K ìµœì í™”"

checkpoint-006: í…ŒìŠ¤íŠ¸ ìŠ¤í™ ì—…ë°ì´íŠ¸
  - ê¸°ì¡´ í…ŒìŠ¤íŠ¸ í˜¸í™˜ì„± í™•ì¸
  - Git commit: "test: 6K ìŠ¤ì¼€ì¼ í…ŒìŠ¤íŠ¸ ìŠ¤í™ ì—…ë°ì´íŠ¸"

checkpoint-007: ì „ì²´ í…ŒìŠ¤íŠ¸ í†µê³¼
  - 93/93 ì„±ê³µ
  - Git commit: "test: Sprint 5 ì „ì²´ í…ŒìŠ¤íŠ¸ í†µê³¼ (6K)"

checkpoint-008: ë¬¸ì„œí™” ì™„ë£Œ
  - ìµœì¢… ë³´ê³ ì„œ 3ê°œ ì‘ì„±
  - Git commit: "docs: Sprint 5 Week 3 Final (70K architecture)"
```

### Rollback Plan
```yaml
if_step_2_fails: # ì•Œê³ ë¦¬ì¦˜ ìµœì í™” ì‹¤íŒ¨
  action: Git revert to checkpoint-004
  alternative: ëŒ€ì•ˆ 2 (Database Migration) ê²€í† 

if_step_4_fails: # í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨
  action:
    - ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸ ë¶„ì„ (ì„±ëŠ¥ vs ë¡œì§)
    - íƒ€ì„ì•„ì›ƒ ì¡°ì • vs ì•Œê³ ë¦¬ì¦˜ ì¬ìµœì í™”
    - checkpoint-005ë¡œ ë³µê·€, Step 2 ì¬ê²€í† 

if_memory_exceeded: # ë©”ëª¨ë¦¬ ì´ˆê³¼
  action: Sparse Matrix threshold ìƒí–¥ (0.01 â†’ 0.05)
  fallback: ëŒ€ì•ˆ 2 (IndexedDB) ì¦‰ì‹œ ì „í™˜
```

---

## âœ… ìŠ¹ì¸ ëŒ€ê¸°

**ê³„íš ìŠ¹ì¸ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [x] 70,000ê°œ ìŠ¤ì¼€ì¼ ëª©í‘œ ëª…í™•í™”
- [x] 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° (SPEC_DRIVEN_WORKFLOW)
- [x] ì—ì´ì „íŠ¸/ëª¨ë“œ/MCP/SC ëª…ë ¹ ì „ëµ
- [x] ë³‘ë ¬ ì‹¤í–‰ ìµœì í™”
- [x] ì•ˆì „ ì¥ì¹˜ (checkpoint, rollback)
- [x] ë¬¸ì„œ ì‘ì—… (claudedocs)

**ìŠ¹ì¸ í›„ ì‹¤í–‰ ìˆœì„œ**:
1. Step 1: CSV íŒŒì´í”„ë¼ì¸ (5ë¶„)
2. Step 2: ì•Œê³ ë¦¬ì¦˜ ìµœì í™” (20ë¶„, ë³‘ë ¬)
3. Step 3: í…ŒìŠ¤íŠ¸ ìŠ¤í™ (10ë¶„)
4. Step 4: ì „ì²´ í…ŒìŠ¤íŠ¸ (15ë¶„)
5. Step 5: ë¬¸ì„œí™” (10ë¶„)

---

**ì‘ì„±ì**: Claude (fenomeno-auto-v9)
**ê²€í† ì**: ì‚¬ìš©ì ìŠ¹ì¸ í•„ìš”
**ë‹¤ìŒ ë‹¨ê³„**: "ê³„íš ìŠ¹ì¸" â†’ Step 1 ì‹¤í–‰
