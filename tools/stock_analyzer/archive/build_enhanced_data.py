#!/usr/bin/env python3
"""
Enhanced Stock Data Builder
Global_Scouter CSV ë°ì´í„°ë¥¼ ì›¹ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í’ë¶€í•œ JSON í˜•íƒœë¡œ ë³€í™˜
"""

import pandas as pd
import json
import os
from pathlib import Path

# ì„¤ì •
CSV_SOURCE_DIR = "../../../../fenomeno_projects/Global_Scouter/Global_Scouter_20251003"
OUTPUT_DIR = "./data"

def load_and_clean_csv(file_path):
    """CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì •ì œ"""
    try:
        # CSV íŒŒì¼ ì½ê¸° (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
        df = pd.read_csv(file_path, encoding='utf-8')
        
        # ë¹ˆ í–‰ ì œê±°
        df = df.dropna(how='all')
        
        # ì²« ë²ˆì§¸ í–‰ì´ í—¤ë” ì„¤ëª…ì¸ ê²½ìš° ì œê±°
        if df.iloc[0, 1] and 'ë°ì´í„°-ëª¨ë‘' in str(df.iloc[0, 1]):
            df = df.drop(0).reset_index(drop=True)
            
        return df
    except Exception as e:
        print(f"Error loading {file_path}: {e}")
        return None

def extract_company_data():
    """A_Company.csvì—ì„œ ê¸°ì—… ë°ì´í„° ì¶”ì¶œ"""
    csv_path = os.path.join(CSV_SOURCE_DIR, "A_Company.csv")
    df = load_and_clean_csv(csv_path)
    
    if df is None:
        return []
    
    print(f"Loaded A_Company.csv with {len(df)} rows and {len(df.columns)} columns")
    print("Column names:", df.columns.tolist()[:10])  # ì²˜ìŒ 10ê°œ ì»¬ëŸ¼ë§Œ ì¶œë ¥
    
    companies = []
    
    for idx, row in df.iterrows():
        try:
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            ticker = str(row.iloc[1]) if pd.notna(row.iloc[1]) else ""
            corp_name = str(row.iloc[2]) if pd.notna(row.iloc[2]) else ""
            exchange = str(row.iloc[3]) if pd.notna(row.iloc[3]) else ""
            industry = str(row.iloc[4]) if pd.notna(row.iloc[4]) else ""
            
            # ë¹ˆ í‹°ì»¤ëŠ” ìŠ¤í‚µ
            if not ticker or ticker == "nan" or ticker == "Ticker":
                continue
                
            # ìˆ«ì ë°ì´í„° ì¶”ì¶œ ë° ë³€í™˜
            def safe_float(value):
                try:
                    if pd.isna(value) or value == "" or str(value).strip() == "":
                        return None
                    # í•œêµ­ ì›í™” í‘œì‹œ ì œê±° (â‚© ê¸°í˜¸ì™€ ì‰¼í‘œ)
                    if isinstance(value, str):
                        value = value.replace('â‚©', '').replace(',', '').strip()
                    return float(value)
                except:
                    return None
            
            # í˜„ì¬ê°€ (ì»¬ëŸ¼ 7)
            current_price = safe_float(row.iloc[7])
            
            # ì‹œê°€ì´ì•¡ (ì»¬ëŸ¼ 10)
            market_cap = safe_float(row.iloc[10])
            
            # ROE (ì»¬ëŸ¼ 11)
            roe_fwd = safe_float(row.iloc[11])
            
            # OPM (ì»¬ëŸ¼ 12)
            opm_fwd = safe_float(row.iloc[12])
            
            # PER (ì»¬ëŸ¼ 14)
            per_current = safe_float(row.iloc[14])
            
            # PBR (ì»¬ëŸ¼ 16)
            pbr_current = safe_float(row.iloc[16])
            
            # ì„±ì¥ë¥  (ì»¬ëŸ¼ 17)
            sales_growth = safe_float(row.iloc[17])
            
            # PER 3ë…„ (ì»¬ëŸ¼ 19)
            per_3y = safe_float(row.iloc[19])
            
            # PER 5ë…„ (ì»¬ëŸ¼ 20)
            per_5y = safe_float(row.iloc[20])
            
            # PEG (ì»¬ëŸ¼ 22)
            peg_ratio = safe_float(row.iloc[22])
            
            # ë°°ë‹¹ìˆ˜ìµë¥  (ì»¬ëŸ¼ 26)
            dividend_yield = safe_float(row.iloc[26])
            
            # ìˆ˜ìµë¥  ë°ì´í„° (ì»¬ëŸ¼ 27-32: 1ì£¼, 1ê°œì›”, 3ê°œì›”, 6ê°œì›”, YTD, 12ê°œì›”)
            returns = {
                "1W": safe_float(row.iloc[27]),
                "1M": safe_float(row.iloc[28]),
                "3M": safe_float(row.iloc[29]),
                "6M": safe_float(row.iloc[30]),
                "YTD": safe_float(row.iloc[31]),
                "12M": safe_float(row.iloc[32])
            }
            
            company_data = {
                "Ticker": ticker,
                "corpName": corp_name,
                "exchange": exchange,
                "industry": industry,
                "currentPrice": current_price,
                "marketCapUSD": market_cap,
                "roeFwd": roe_fwd,
                "opmFwd": opm_fwd,
                "perCurrent": per_current,
                "pbrCurrent": pbr_current,
                "salesGrowth": sales_growth,
                "per3Y": per_3y,
                "per5Y": per_5y,
                "pegRatio": peg_ratio,
                "dividendYield": dividend_yield,
                "returns": returns,
                # ê²€ìƒ‰ ìµœì í™”ìš©
                "searchIndex": f"{ticker} {corp_name}".lower()
            }
            
            companies.append(company_data)
            
        except Exception as e:
            print(f"Error processing row {idx}: {e}")
            continue
    
    print(f"Successfully processed {len(companies)} companies")
    return companies

def remove_duplicates(companies):
    """ì¤‘ë³µ ì œê±° (ê°™ì€ Ticker)"""
    seen_tickers = set()
    unique_companies = []
    
    for company in companies:
        ticker = company["Ticker"]
        if ticker not in seen_tickers:
            seen_tickers.add(ticker)
            unique_companies.append(company)
        else:
            print(f"Duplicate removed: {ticker}")
    
    print(f"Removed {len(companies) - len(unique_companies)} duplicates")
    return unique_companies

def analyze_data_quality(companies):
    """ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
    print("\n=== ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ===")
    print(f"ì´ ê¸°ì—… ìˆ˜: {len(companies)}")
    
    # ê±°ë˜ì†Œë³„ ë¶„í¬
    exchanges = {}
    for company in companies:
        exchange = company["exchange"]
        exchanges[exchange] = exchanges.get(exchange, 0) + 1
    
    print("\nê±°ë˜ì†Œë³„ ë¶„í¬:")
    for exchange, count in sorted(exchanges.items(), key=lambda x: x[1], reverse=True):
        print(f"  {exchange}: {count}ê°œ")
    
    # ì—…ì¢…ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ)
    industries = {}
    for company in companies:
        industry = company["industry"]
        industries[industry] = industries.get(industry, 0) + 1
    
    print("\nì—…ì¢…ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
    for industry, count in sorted(industries.items(), key=lambda x: x[1], reverse=True)[:10]:
        print(f"  {industry}: {count}ê°œ")
    
    # ë°ì´í„° ì™„ì„±ë„
    fields = ["marketCapUSD", "roeFwd", "perCurrent", "pbrCurrent"]
    print("\në°ì´í„° ì™„ì„±ë„:")
    for field in fields:
        non_null_count = sum(1 for c in companies if c[field] is not None)
        percentage = (non_null_count / len(companies)) * 100
        print(f"  {field}: {non_null_count}/{len(companies)} ({percentage:.1f}%)")

def save_enhanced_data(companies):
    """í–¥ìƒëœ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
    
    # ë©”ì¸ ë°ì´í„° ì €ì¥
    output_path = os.path.join(OUTPUT_DIR, "summary_data.json")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(companies, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… Enhanced data saved to {output_path}")
    print(f"   File size: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB")
    
    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
    if companies:
        print(f"\nğŸ“Š Sample company data:")
        sample = companies[0]
        for key, value in sample.items():
            if key != "returns":
                print(f"   {key}: {value}")
            else:
                print(f"   returns: {value}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Enhanced Stock Data Builder ì‹œì‘")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # 1. ê¸°ì—… ë°ì´í„° ì¶”ì¶œ
    print("\n1ï¸âƒ£ A_Company.csvì—ì„œ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
    companies = extract_company_data()
    
    if not companies:
        print("âŒ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")
        return
    
    # 2. ì¤‘ë³µ ì œê±°
    print("\n2ï¸âƒ£ ì¤‘ë³µ ë°ì´í„° ì œê±° ì¤‘...")
    companies = remove_duplicates(companies)
    
    # 3. ë°ì´í„° í’ˆì§ˆ ë¶„ì„
    analyze_data_quality(companies)
    
    # 4. JSON ì €ì¥
    print("\n3ï¸âƒ£ JSON íŒŒì¼ ì €ì¥ ì¤‘...")
    save_enhanced_data(companies)
    
    print("\nğŸ‰ ì™„ë£Œ!")

if __name__ == "__main__":
    main()