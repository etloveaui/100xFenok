# ğŸ“Š ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—°ë™ ì™„ì „ ê°€ì´ë“œ

## ğŸ¯ ê°œìš”
ë¯¸ì•¼ì½”ì§€ë§ˆ POI ë°ì´í„°ë¥¼ Google Sheets ë° Excel Onlineê³¼ ì—°ë™í•˜ì—¬ ì‹¤ì‹œê°„ ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•

**í˜„ì¬ ë°ì´í„°**: âœ… 100ê°œ POI (Phase 4 ì™„ë£Œ)  
**ëª©í‘œ**: ìŠ¤í”„ë ˆë“œì‹œíŠ¸ â†” JSON ì–‘ë°©í–¥ ì‹¤ì‹œê°„ ë™ê¸°í™”

---

## ğŸš€ Quick Start (30ë¶„ ì„¤ì •)

### 1ë‹¨ê³„: Google Cloud ì„¤ì • (10ë¶„)
1. [Google Cloud Console](https://console.cloud.google.com/) ì ‘ì†
2. ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±: "miyakojima-poi-sync"
3. API ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ "Google Sheets API" í™œì„±í™”
4. API ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ "Google Drive API" í™œì„±í™”
5. ì„œë¹„ìŠ¤ ê³„ì • ìƒì„±:
   - IAM ë° ê´€ë¦¬ì > ì„œë¹„ìŠ¤ ê³„ì • > ì„œë¹„ìŠ¤ ê³„ì • ë§Œë“¤ê¸°
   - ì´ë¦„: "poi-sync-service"
   - ì—­í• : "í¸ì§‘ì"
   - JSON í‚¤ ë‹¤ìš´ë¡œë“œ â†’ `credentials.json`ìœ¼ë¡œ ì €ì¥

### 2ë‹¨ê³„: ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„± (5ë¶„)
1. [Google Sheets](https://sheets.google.com) ì—ì„œ ìƒˆ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„±
2. ì´ë¦„: "Miyakojima POI Database"
3. ì²« ë²ˆì§¸ ì‹œíŠ¸ ì´ë¦„: "POIs"
4. ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ ì£¼ì†Œì™€ ê³µìœ  (í¸ì§‘ ê¶Œí•œ)

### 3ë‹¨ê³„: Python í™˜ê²½ ì„¤ì • (10ë¶„)
```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv poi_sync_env
poi_sync_env\Scripts\activate  # Windows
# source poi_sync_env/bin/activate  # macOS/Linux

# í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install gspread google-auth pandas openpyxl
```

### 4ë‹¨ê³„: ì¦‰ì‹œ ì‹¤í–‰ (5ë¶„)
```bash
# ì´ˆê¸° ë°ì´í„° ì—…ë¡œë“œ
python upload_to_sheets.py

# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘
python monitor_changes.py
```

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
miyakojima-web/
â”œâ”€â”€ ğŸ“„ credentials.json              # Google ì„œë¹„ìŠ¤ ê³„ì • í‚¤ (ë³´ì•ˆ ì£¼ì˜!)
â”œâ”€â”€ ğŸ“„ sheets_config.py              # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì„¤ì •
â”œâ”€â”€ ğŸ“„ google_sheets_client.py       # Google Sheets API í´ë¼ì´ì–¸íŠ¸
â”œâ”€â”€ ğŸ“„ excel_online_client.py        # Excel Online API í´ë¼ì´ì–¸íŠ¸  
â”œâ”€â”€ ğŸ“„ upload_to_sheets.py           # JSON â†’ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—…ë¡œë“œ
â”œâ”€â”€ ğŸ“„ download_from_sheets.py       # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ â†’ JSON ë‹¤ìš´ë¡œë“œ
â”œâ”€â”€ ğŸ“„ monitor_changes.py            # ì‹¤ì‹œê°„ ë³€ê²½ì‚¬í•­ ëª¨ë‹ˆí„°ë§
â”œâ”€â”€ ğŸ“„ sync_scheduler.py             # ìë™ ë™ê¸°í™” ìŠ¤ì¼€ì¤„ëŸ¬
â””â”€â”€ ğŸ“„ validation_utils.py           # ë°ì´í„° ê²€ì¦ ìœ í‹¸ë¦¬í‹°
```

---

## ğŸ”§ í•µì‹¬ êµ¬í˜„ ì½”ë“œ

### sheets_config.py
```python
"""ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—°ë™ ì„¤ì •"""

# Google Sheets ì„¤ì •
CREDENTIALS_FILE = 'credentials.json'
SPREADSHEET_ID = 'your-google-sheet-id'  # URLì—ì„œ ì¶”ì¶œ
WORKSHEET_NAME = 'POIs'

# Excel Online ì„¤ì • (ì„ íƒì‚¬í•­)
EXCEL_TENANT_ID = 'your-tenant-id'
EXCEL_CLIENT_ID = 'your-client-id'
EXCEL_CLIENT_SECRET = 'your-client-secret'

# ë™ê¸°í™” ì„¤ì •
SYNC_INTERVAL = 300  # 5ë¶„ë§ˆë‹¤ ë™ê¸°í™”
BACKUP_ENABLED = True
MAX_RETRIES = 3

# POI ë°ì´í„° ìŠ¤í‚¤ë§ˆ
POI_COLUMNS = [
    'id',
    'name', 
    'name_en',
    'category',
    'subcategory',
    'rating',
    'review_count',
    'latitude',
    'longitude',
    'address',
    'phone',
    'website',
    'description',
    'opening_hours',
    'price_range',
    'amenities',
    'weather_dependent',
    'best_time',
    'created_at',
    'updated_at',
    'status'
]

# ì¹´í…Œê³ ë¦¬ ìœ íš¨ì„± ê²€ì‚¬
VALID_CATEGORIES = [
    'beaches', 'culture', 'activities', 
    'restaurants', 'nature', 'shopping'
]

# ë¯¸ì•¼ì½”ì§€ë§ˆ ì¢Œí‘œ ë²”ìœ„
COORDINATE_BOUNDS = {
    'lat_min': 24.6,
    'lat_max': 24.9, 
    'lng_min': 125.1,
    'lng_max': 125.5
}
```

### google_sheets_client.py
```python
"""Google Sheets API í´ë¼ì´ì–¸íŠ¸"""

import gspread
import json
import pandas as pd
from google.oauth2.service_account import Credentials
from datetime import datetime
from sheets_config import *

class GoogleSheetsClient:
    def __init__(self):
        """Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        scope = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        
        try:
            credentials = Credentials.from_service_account_file(
                CREDENTIALS_FILE, scopes=scope
            )
            self.client = gspread.authorize(credentials)
            self.spreadsheet = self.client.open_by_key(SPREADSHEET_ID)
            print("âœ… Google Sheets ì—°ê²° ì„±ê³µ")
        except Exception as e:
            print(f"âŒ Google Sheets ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
    
    def upload_poi_data(self, poi_list):
        """POI ë°ì´í„°ë¥¼ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ì—…ë¡œë“œ"""
        try:
            worksheet = self.spreadsheet.worksheet(WORKSHEET_NAME)
            
            # ê¸°ì¡´ ë°ì´í„° ë°±ì—…
            if BACKUP_ENABLED:
                self._create_backup()
            
            # ì›Œí¬ì‹œíŠ¸ ì´ˆê¸°í™”
            worksheet.clear()
            
            # í—¤ë” ì¶”ê°€
            worksheet.append_row(POI_COLUMNS)
            
            # POI ë°ì´í„° ì¶”ê°€
            for poi in poi_list:
                row = self._poi_to_row(poi)
                worksheet.append_row(row)
            
            # í¬ë§·íŒ… ì ìš©
            self._apply_formatting(worksheet)
            
            print(f"âœ… {len(poi_list)}ê°œ POI ì—…ë¡œë“œ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def download_poi_data(self):
        """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ POI ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        try:
            worksheet = self.spreadsheet.worksheet(WORKSHEET_NAME)
            records = worksheet.get_all_records()
            
            poi_list = []
            for record in records:
                poi = self._row_to_poi(record)
                if poi:  # ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼
                    poi_list.append(poi)
            
            print(f"âœ… {len(poi_list)}ê°œ POI ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
            return poi_list
            
        except Exception as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def get_last_modified(self):
        """ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„ í™•ì¸"""
        try:
            worksheet = self.spreadsheet.worksheet(WORKSHEET_NAME)
            # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ì„ ë³„ë„ ì…€ì— ì €ì¥
            last_modified = worksheet.cell(1, len(POI_COLUMNS) + 1).value
            if last_modified:
                return datetime.fromisoformat(last_modified)
            return None
        except:
            return None
    
    def update_last_modified(self):
        """ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„ ì—…ë°ì´íŠ¸"""
        try:
            worksheet = self.spreadsheet.worksheet(WORKSHEET_NAME)
            current_time = datetime.now().isoformat()
            worksheet.update_cell(1, len(POI_COLUMNS) + 1, current_time)
        except Exception as e:
            print(f"âš ï¸ ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _poi_to_row(self, poi):
        """POI ê°ì²´ë¥¼ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ í–‰ìœ¼ë¡œ ë³€í™˜"""
        row = []
        for column in POI_COLUMNS:
            value = poi.get(column, '')
            
            # íŠ¹ë³„í•œ ì²˜ë¦¬ê°€ í•„ìš”í•œ í•„ë“œë“¤
            if column == 'coordinates' and isinstance(value, list):
                # coordinatesëŠ” latitude, longitudeë¡œ ë¶„ë¦¬
                continue
            elif column == 'latitude':
                value = poi.get('coordinates', [0, 0])[0]
            elif column == 'longitude':
                value = poi.get('coordinates', [0, 0])[1]
            elif column in ['opening_hours', 'amenities', 'best_time']:
                # JSON í•„ë“œëŠ” ë¬¸ìì—´ë¡œ ì €ì¥
                value = json.dumps(value) if value else ''
            elif column == 'created_at':
                value = datetime.now().isoformat()
            elif column == 'updated_at':
                value = datetime.now().isoformat()
            elif column == 'status':
                value = 'active'
            
            row.append(str(value) if value is not None else '')
        
        return row
    
    def _row_to_poi(self, record):
        """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ í–‰ì„ POI ê°ì²´ë¡œ ë³€í™˜"""
        try:
            poi = {
                'id': record.get('id'),
                'name': record.get('name'),
                'name_en': record.get('name_en'),
                'category': record.get('category'),
                'subcategory': record.get('subcategory'),
                'rating': float(record.get('rating', 0)),
                'review_count': int(record.get('review_count', 0)),
                'coordinates': [
                    float(record.get('latitude', 0)),
                    float(record.get('longitude', 0))
                ],
                'address': record.get('address'),
                'phone': record.get('phone'),
                'website': record.get('website'),
                'description': record.get('description'),
                'price_range': record.get('price_range'),
                'weather_dependent': record.get('weather_dependent', '').lower() == 'true'
            }
            
            # JSON í•„ë“œ íŒŒì‹±
            for field in ['opening_hours', 'amenities', 'best_time']:
                value = record.get(field, '')
                if value:
                    try:
                        poi[field] = json.loads(value)
                    except:
                        poi[field] = value.split(',') if ',' in value else [value]
                else:
                    poi[field] = []
            
            # ìœ íš¨ì„± ê²€ì‚¬
            if self._validate_poi(poi):
                return poi
            else:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ POI: {poi.get('id', 'Unknown')}")
                return None
                
        except Exception as e:
            print(f"âŒ POI ë³€í™˜ ì˜¤ë¥˜: {e}")
            return None
    
    def _validate_poi(self, poi):
        """POI ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬"""
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = ['id', 'name', 'category', 'coordinates']
        for field in required_fields:
            if not poi.get(field):
                return False
        
        # ì¹´í…Œê³ ë¦¬ ìœ íš¨ì„±
        if poi['category'] not in VALID_CATEGORIES:
            return False
        
        # ì¢Œí‘œ ìœ íš¨ì„±
        lat, lng = poi['coordinates']
        if not (COORDINATE_BOUNDS['lat_min'] <= lat <= COORDINATE_BOUNDS['lat_max']):
            return False
        if not (COORDINATE_BOUNDS['lng_min'] <= lng <= COORDINATE_BOUNDS['lng_max']):
            return False
        
        # í‰ì  ìœ íš¨ì„±
        rating = poi.get('rating', 0)
        if not (0 <= rating <= 5):
            return False
        
        return True
    
    def _apply_formatting(self, worksheet):
        """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ í¬ë§·íŒ… ì ìš©"""
        try:
            # í—¤ë” ì„œì‹
            worksheet.format('1:1', {
                'backgroundColor': {'red': 0.2, 'green': 0.6, 'blue': 1.0},
                'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}}
            })
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            worksheet.columns_auto_resize(0, len(POI_COLUMNS))
            
        except Exception as e:
            print(f"âš ï¸ í¬ë§·íŒ… ì ìš© ì‹¤íŒ¨: {e}")
    
    def _create_backup(self):
        """í˜„ì¬ ë°ì´í„° ë°±ì—…"""
        try:
            # ë°±ì—… ì‹œíŠ¸ ìƒì„±
            backup_name = f"Backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            current_worksheet = self.spreadsheet.worksheet(WORKSHEET_NAME)
            
            # í˜„ì¬ ë°ì´í„°ë¥¼ ë°±ì—… ì‹œíŠ¸ë¡œ ë³µì‚¬
            backup_worksheet = self.spreadsheet.duplicate_sheet(
                current_worksheet.id, new_sheet_name=backup_name
            )
            
            print(f"ğŸ“‹ ë°±ì—… ìƒì„±: {backup_name}")
            
        except Exception as e:
            print(f"âš ï¸ ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
```

### upload_to_sheets.py
```python
"""JSON ë°ì´í„°ë¥¼ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ì—…ë¡œë“œ"""

import json
from google_sheets_client import GoogleSheetsClient

def upload_current_poi_data():
    """í˜„ì¬ POI JSON ë°ì´í„°ë¥¼ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ì—…ë¡œë“œ"""
    
    # JSON íŒŒì¼ ì½ê¸°
    try:
        with open('data/miyakojima_pois.json', 'r', encoding='utf-8') as f:
            poi_data = json.load(f)
        print(f"ğŸ“– {len(poi_data)}ê°œ POI ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ JSON íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return False
    
    # Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    try:
        sheets_client = GoogleSheetsClient()
    except Exception as e:
        print(f"âŒ Google Sheets ì—°ê²° ì‹¤íŒ¨: {e}")
        return False
    
    # ë°ì´í„° ì—…ë¡œë“œ
    success = sheets_client.upload_poi_data(poi_data)
    
    if success:
        # ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„ ì—…ë°ì´íŠ¸
        sheets_client.update_last_modified()
        print("ğŸ‰ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—…ë¡œë“œ ì™„ë£Œ!")
        print(f"ğŸ“Š ì´ {len(poi_data)}ê°œ POI ë°ì´í„°ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        category_stats = {}
        for poi in poi_data:
            category = poi.get('category', 'unknown')
            category_stats[category] = category_stats.get(category, 0) + 1
        
        print("\nğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ í†µê³„:")
        for category, count in sorted(category_stats.items()):
            print(f"  {category}: {count}ê°œ")
        
        return True
    else:
        print("âŒ ì—…ë¡œë“œ ì‹¤íŒ¨")
        return False

if __name__ == "__main__":
    print("ğŸš€ ë¯¸ì•¼ì½”ì§€ë§ˆ POI ë°ì´í„° ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—…ë¡œë“œ ì‹œì‘")
    print("=" * 50)
    
    upload_current_poi_data()
```

### download_from_sheets.py
```python
"""ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ JSON ë°ì´í„°ë¡œ ë‹¤ìš´ë¡œë“œ"""

import json
import os
from datetime import datetime
from google_sheets_client import GoogleSheetsClient

def download_and_update_json():
    """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ JSON íŒŒì¼ ì—…ë°ì´íŠ¸"""
    
    # Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    try:
        sheets_client = GoogleSheetsClient()
    except Exception as e:
        print(f"âŒ Google Sheets ì—°ê²° ì‹¤íŒ¨: {e}")
        return False
    
    # ë³€ê²½ì‚¬í•­ í™•ì¸
    last_modified = sheets_client.get_last_modified()
    json_modified = get_json_last_modified()
    
    if last_modified and json_modified and last_modified <= json_modified:
        print("ğŸ“ ë³€ê²½ì‚¬í•­ ì—†ìŒ - ìŠ¤í‚µ")
        return True
    
    # ê¸°ì¡´ JSON ë°±ì—…
    backup_json()
    
    # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    poi_data = sheets_client.download_poi_data()
    
    if not poi_data:
        print("âŒ ë‹¤ìš´ë¡œë“œëœ ë°ì´í„° ì—†ìŒ")
        return False
    
    # JSON íŒŒì¼ ì €ì¥
    try:
        with open('data/miyakojima_pois.json', 'w', encoding='utf-8') as f:
            json.dump(poi_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… {len(poi_data)}ê°œ POI ë°ì´í„° JSON ì €ì¥ ì™„ë£Œ")
        
        # ë°ì´í„° í’ˆì§ˆ í™•ì¸
        quality_report = validate_downloaded_data(poi_data)
        print(f"ğŸ“Š ë°ì´í„° í’ˆì§ˆ: {quality_report['score']:.1f}%")
        
        return True
        
    except Exception as e:
        print(f"âŒ JSON ì €ì¥ ì‹¤íŒ¨: {e}")
        restore_backup()
        return False

def get_json_last_modified():
    """JSON íŒŒì¼ì˜ ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„ í™•ì¸"""
    try:
        stat = os.stat('data/miyakojima_pois.json')
        return datetime.fromtimestamp(stat.st_mtime)
    except:
        return None

def backup_json():
    """í˜„ì¬ JSON íŒŒì¼ ë°±ì—…"""
    try:
        if os.path.exists('data/miyakojima_pois.json'):
            backup_name = f"data/backup_pois_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            os.rename('data/miyakojima_pois.json', backup_name)
            print(f"ğŸ“‹ JSON ë°±ì—…: {backup_name}")
    except Exception as e:
        print(f"âš ï¸ JSON ë°±ì—… ì‹¤íŒ¨: {e}")

def restore_backup():
    """ë°±ì—…ì—ì„œ JSON ë³µì›"""
    try:
        # ê°€ì¥ ìµœê·¼ ë°±ì—… íŒŒì¼ ì°¾ê¸°
        backup_files = [f for f in os.listdir('data/') if f.startswith('backup_pois_')]
        if backup_files:
            latest_backup = sorted(backup_files)[-1]
            os.rename(f"data/{latest_backup}", 'data/miyakojima_pois.json')
            print(f"ğŸ”„ ë°±ì—…ì—ì„œ ë³µì›: {latest_backup}")
    except Exception as e:
        print(f"âŒ ë°±ì—… ë³µì› ì‹¤íŒ¨: {e}")

def validate_downloaded_data(poi_data):
    """ë‹¤ìš´ë¡œë“œëœ ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
    total_count = len(poi_data)
    valid_count = 0
    category_count = {}
    
    for poi in poi_data:
        # ê¸°ë³¸ ìœ íš¨ì„± ê²€ì‚¬
        if (poi.get('id') and poi.get('name') and 
            poi.get('category') and poi.get('coordinates')):
            valid_count += 1
            
            # ì¹´í…Œê³ ë¦¬ í†µê³„
            category = poi['category']
            category_count[category] = category_count.get(category, 0) + 1
    
    quality_score = (valid_count / total_count * 100) if total_count > 0 else 0
    
    report = {
        'total': total_count,
        'valid': valid_count,
        'score': quality_score,
        'categories': category_count
    }
    
    print("\nğŸ“ˆ ë‹¤ìš´ë¡œë“œ ë°ì´í„° ë¶„ì„:")
    print(f"  ì´ POI: {total_count}ê°œ")
    print(f"  ìœ íš¨ POI: {valid_count}ê°œ")
    print(f"  í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}%")
    print(f"  ì¹´í…Œê³ ë¦¬: {len(category_count)}ê°œ")
    
    return report

if __name__ == "__main__":
    print("ğŸ“¥ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ POI ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘")
    print("=" * 50)
    
    download_and_update_json()
```

### monitor_changes.py
```python
"""ì‹¤ì‹œê°„ ë³€ê²½ì‚¬í•­ ëª¨ë‹ˆí„°ë§"""

import time
import json
from datetime import datetime
from google_sheets_client import GoogleSheetsClient

class ChangeMonitor:
    def __init__(self):
        self.sheets_client = GoogleSheetsClient()
        self.last_check = datetime.now()
        self.monitoring = False
    
    def start_monitoring(self, interval=300):
        """ë³€ê²½ì‚¬í•­ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ê¸°ë³¸ 5ë¶„ ê°„ê²©)"""
        print(f"ğŸ” ë³€ê²½ì‚¬í•­ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ê°„ê²©: {interval}ì´ˆ)")
        self.monitoring = True
        
        try:
            while self.monitoring:
                self.check_for_changes()
                time.sleep(interval)
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨ë¨")
            self.monitoring = False
    
    def check_for_changes(self):
        """ë³€ê²½ì‚¬í•­ í™•ì¸ ë° ì²˜ë¦¬"""
        current_time = datetime.now()
        print(f"\nğŸ” ë³€ê²½ì‚¬í•­ í™•ì¸ ì¤‘... ({current_time.strftime('%Y-%m-%d %H:%M:%S')})")
        
        # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„ í™•ì¸
        sheet_modified = self.sheets_client.get_last_modified()
        
        if sheet_modified and sheet_modified > self.last_check:
            print("ğŸ”„ ë³€ê²½ì‚¬í•­ ê°ì§€! ë™ê¸°í™” ì‹œì‘...")
            
            # ë³€ê²½ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            from download_from_sheets import download_and_update_json
            success = download_and_update_json()
            
            if success:
                print("âœ… ë™ê¸°í™” ì™„ë£Œ")
                # ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë³€ê²½ ì•Œë¦¼ (ì„ íƒì‚¬í•­)
                self.notify_web_app()
            else:
                print("âŒ ë™ê¸°í™” ì‹¤íŒ¨")
            
            self.last_check = current_time
        else:
            print("ğŸ“ ë³€ê²½ì‚¬í•­ ì—†ìŒ")
    
    def notify_web_app(self):
        """ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë°ì´í„° ë³€ê²½ ì•Œë¦¼"""
        try:
            # ë³€ê²½ ì•Œë¦¼ íŒŒì¼ ìƒì„± (ì›¹ì•±ì—ì„œ pollingìœ¼ë¡œ í™•ì¸)
            notification = {
                'timestamp': datetime.now().isoformat(),
                'type': 'poi_data_updated',
                'message': 'POI ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.'
            }
            
            with open('data/update_notification.json', 'w', encoding='utf-8') as f:
                json.dump(notification, f, ensure_ascii=False, indent=2)
            
            print("ğŸ“¢ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë³€ê²½ ì•Œë¦¼ ì „ì†¡")
            
        except Exception as e:
            print(f"âš ï¸ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
    
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨"""
        self.monitoring = False
        print("â¹ï¸ ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨")

if __name__ == "__main__":
    print("ğŸ” ë¯¸ì•¼ì½”ì§€ë§ˆ POI ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    print("=" * 50)
    print("Ctrl+Cë¡œ ì¤‘ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    monitor = ChangeMonitor()
    monitor.start_monitoring(interval=300)  # 5ë¶„ë§ˆë‹¤ í™•ì¸
```

### sync_scheduler.py
```python
"""ìë™ ë™ê¸°í™” ìŠ¤ì¼€ì¤„ëŸ¬"""

import schedule
import time
from datetime import datetime
from upload_to_sheets import upload_current_poi_data
from download_from_sheets import download_and_update_json

class SyncScheduler:
    def __init__(self):
        self.setup_schedules()
    
    def setup_schedules(self):
        """ë™ê¸°í™” ìŠ¤ì¼€ì¤„ ì„¤ì •"""
        # ë§¤ì¼ ì˜¤ì „ 3ì‹œ ì „ì²´ ì—…ë¡œë“œ (JSON â†’ ìŠ¤í”„ë ˆë“œì‹œíŠ¸)
        schedule.every().day.at("03:00").do(self.full_upload)
        
        # ë§¤ì‹œê°„ ë³€ê²½ì‚¬í•­ ë‹¤ìš´ë¡œë“œ (ìŠ¤í”„ë ˆë“œì‹œíŠ¸ â†’ JSON)
        schedule.every().hour.do(self.incremental_download)
        
        # ë§¤ì¼ ì˜¤í›„ 9ì‹œ í’ˆì§ˆ ê²€ì‚¬
        schedule.every().day.at("21:00").do(self.quality_check)
        
        print("â° ë™ê¸°í™” ìŠ¤ì¼€ì¤„ ì„¤ì • ì™„ë£Œ")
        print("  - 03:00: ì „ì²´ ì—…ë¡œë“œ (JSON â†’ ì‹œíŠ¸)")
        print("  - ë§¤ì‹œê°„: ë³€ê²½ì‚¬í•­ ë‹¤ìš´ë¡œë“œ (ì‹œíŠ¸ â†’ JSON)")
        print("  - 21:00: ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬")
    
    def full_upload(self):
        """ì „ì²´ ë°ì´í„° ì—…ë¡œë“œ"""
        print(f"\nğŸš€ ì˜ˆì•½ ì—…ë¡œë“œ ì‹œì‘ - {datetime.now()}")
        try:
            success = upload_current_poi_data()
            if success:
                self.log_sync_result("upload", "success")
            else:
                self.log_sync_result("upload", "failed")
        except Exception as e:
            print(f"âŒ ì˜ˆì•½ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
            self.log_sync_result("upload", "error", str(e))
    
    def incremental_download(self):
        """ì¦ë¶„ ë‹¤ìš´ë¡œë“œ"""
        print(f"\nğŸ“¥ ì˜ˆì•½ ë‹¤ìš´ë¡œë“œ ì‹œì‘ - {datetime.now()}")
        try:
            success = download_and_update_json()
            if success:
                self.log_sync_result("download", "success")
            else:
                self.log_sync_result("download", "failed")
        except Exception as e:
            print(f"âŒ ì˜ˆì•½ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            self.log_sync_result("download", "error", str(e))
    
    def quality_check(self):
        """ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬"""
        print(f"\nğŸ” í’ˆì§ˆ ê²€ì‚¬ ì‹œì‘ - {datetime.now()}")
        try:
            from validation_utils import run_quality_check
            report = run_quality_check()
            self.log_sync_result("quality_check", "completed", f"Score: {report['score']}")
        except Exception as e:
            print(f"âŒ í’ˆì§ˆ ê²€ì‚¬ ì˜¤ë¥˜: {e}")
            self.log_sync_result("quality_check", "error", str(e))
    
    def log_sync_result(self, operation, status, details=""):
        """ë™ê¸°í™” ê²°ê³¼ ë¡œê¹…"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'operation': operation,
            'status': status,
            'details': details
        }
        
        try:
            import json
            import os
            
            log_file = 'logs/sync_log.json'
            
            # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs('logs', exist_ok=True)
            
            # ê¸°ì¡´ ë¡œê·¸ ì½ê¸°
            if os.path.exists(log_file):
                with open(log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
            else:
                logs = []
            
            # ìƒˆ ë¡œê·¸ ì¶”ê°€
            logs.append(log_entry)
            
            # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
            if len(logs) > 100:
                logs = logs[-100:]
            
            # ë¡œê·¸ ì €ì¥
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(logs, f, ensure_ascii=False, indent=2)
            
        except Exception as e:
            print(f"âš ï¸ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        print("â–¶ï¸ ìë™ ë™ê¸°í™” ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")
        
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ìŠ¤ì¼€ì¤„ í™•ì¸
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ë‹¨ë¨")

if __name__ == "__main__":
    print("â° ë¯¸ì•¼ì½”ì§€ë§ˆ POI ìë™ ë™ê¸°í™” ìŠ¤ì¼€ì¤„ëŸ¬")
    print("=" * 50)
    print("Ctrl+Cë¡œ ì¤‘ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    scheduler = SyncScheduler()
    scheduler.start()
```

### validation_utils.py
```python
"""ë°ì´í„° ê²€ì¦ ìœ í‹¸ë¦¬í‹°"""

import json
import os
from datetime import datetime
from sheets_config import VALID_CATEGORIES, COORDINATE_BOUNDS

def run_quality_check():
    """ì „ì²´ ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬"""
    print("ğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ ì‹œì‘...")
    
    # JSON íŒŒì¼ ì½ê¸°
    try:
        with open('data/miyakojima_pois.json', 'r', encoding='utf-8') as f:
            pois = json.load(f)
    except Exception as e:
        return {'score': 0, 'error': f"JSON ì½ê¸° ì‹¤íŒ¨: {e}"}
    
    total_count = len(pois)
    issues = []
    
    # ê° POI ê²€ì¦
    valid_count = 0
    for i, poi in enumerate(pois):
        poi_issues = validate_single_poi(poi, i)
        if not poi_issues:
            valid_count += 1
        else:
            issues.extend(poi_issues)
    
    # ì¹´í…Œê³ ë¦¬ ê· í˜• ê²€ì‚¬
    category_distribution = check_category_balance(pois)
    
    # ì¤‘ë³µ ID ê²€ì‚¬
    duplicate_ids = check_duplicate_ids(pois)
    if duplicate_ids:
        issues.append(f"ì¤‘ë³µ ID ë°œê²¬: {duplicate_ids}")
    
    # ì¢Œí‘œ í´ëŸ¬ìŠ¤í„°ë§ ê²€ì‚¬
    coordinate_issues = check_coordinate_clustering(pois)
    issues.extend(coordinate_issues)
    
    # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    quality_score = calculate_quality_score(
        valid_count, total_count, len(issues), category_distribution
    )
    
    # ë³´ê³ ì„œ ìƒì„±
    report = {
        'timestamp': datetime.now().isoformat(),
        'total_pois': total_count,
        'valid_pois': valid_count,
        'issues_count': len(issues),
        'issues': issues[:10],  # ìƒìœ„ 10ê°œ ì´ìŠˆë§Œ
        'category_distribution': category_distribution,
        'score': quality_score,
        'grade': get_quality_grade(quality_score)
    }
    
    # ë³´ê³ ì„œ ì €ì¥
    save_quality_report(report)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ“Š í’ˆì§ˆ ê²€ì‚¬ ì™„ë£Œ:")
    print(f"  ì´ POI: {total_count}ê°œ")
    print(f"  ìœ íš¨ POI: {valid_count}ê°œ")
    print(f"  ì´ìŠˆ: {len(issues)}ê°œ")
    print(f"  í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}%")
    print(f"  ë“±ê¸‰: {report['grade']}")
    
    return report

def validate_single_poi(poi, index):
    """ê°œë³„ POI ê²€ì¦"""
    issues = []
    poi_id = poi.get('id', f'index_{index}')
    
    # í•„ìˆ˜ í•„ë“œ í™•ì¸
    required_fields = ['id', 'name', 'category', 'coordinates', 'rating']
    for field in required_fields:
        if not poi.get(field):
            issues.append(f"POI {poi_id}: {field} ëˆ„ë½")
    
    # ì¹´í…Œê³ ë¦¬ ìœ íš¨ì„±
    category = poi.get('category')
    if category and category not in VALID_CATEGORIES:
        issues.append(f"POI {poi_id}: ìœ íš¨í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ '{category}'")
    
    # ì¢Œí‘œ ìœ íš¨ì„±
    coordinates = poi.get('coordinates')
    if coordinates and len(coordinates) == 2:
        lat, lng = coordinates
        if not (COORDINATE_BOUNDS['lat_min'] <= lat <= COORDINATE_BOUNDS['lat_max']):
            issues.append(f"POI {poi_id}: ìœ„ë„ ë²”ìœ„ ë²—ì–´ë‚¨ {lat}")
        if not (COORDINATE_BOUNDS['lng_min'] <= lng <= COORDINATE_BOUNDS['lng_max']):
            issues.append(f"POI {poi_id}: ê²½ë„ ë²”ìœ„ ë²—ì–´ë‚¨ {lng}")
    
    # í‰ì  ìœ íš¨ì„±
    rating = poi.get('rating')
    if rating and not (0 <= rating <= 5):
        issues.append(f"POI {poi_id}: í‰ì  ë²”ìœ„ ë²—ì–´ë‚¨ {rating}")
    
    # ì´ë¦„ ê¸¸ì´ í™•ì¸
    name = poi.get('name', '')
    if len(name) > 100:
        issues.append(f"POI {poi_id}: ì´ë¦„ì´ ë„ˆë¬´ ê¸¸ìŒ ({len(name)}ì)")
    
    return issues

def check_category_balance(pois):
    """ì¹´í…Œê³ ë¦¬ ê· í˜• ê²€ì‚¬"""
    category_count = {}
    for poi in pois:
        category = poi.get('category', 'unknown')
        category_count[category] = category_count.get(category, 0) + 1
    
    total = len(pois)
    distribution = {}
    for category, count in category_count.items():
        percentage = (count / total * 100) if total > 0 else 0
        distribution[category] = {
            'count': count,
            'percentage': round(percentage, 1)
        }
    
    return distribution

def check_duplicate_ids(pois):
    """ì¤‘ë³µ ID ê²€ì‚¬"""
    seen_ids = set()
    duplicates = []
    
    for poi in pois:
        poi_id = poi.get('id')
        if poi_id in seen_ids:
            duplicates.append(poi_id)
        else:
            seen_ids.add(poi_id)
    
    return duplicates

def check_coordinate_clustering(pois):
    """ì¢Œí‘œ í´ëŸ¬ìŠ¤í„°ë§ ê²€ì‚¬ (ë„ˆë¬´ ê°€ê¹Œìš´ POI ê°ì§€)"""
    issues = []
    threshold = 0.001  # ì•½ 100m
    
    for i, poi1 in enumerate(pois):
        for j, poi2 in enumerate(pois[i+1:], i+1):
            coords1 = poi1.get('coordinates', [0, 0])
            coords2 = poi2.get('coordinates', [0, 0])
            
            # ê±°ë¦¬ ê³„ì‚° (ê°„ë‹¨í•œ ìœ í´ë¦¬ë“œ ê±°ë¦¬)
            distance = ((coords1[0] - coords2[0])**2 + (coords1[1] - coords2[1])**2)**0.5
            
            if distance < threshold:
                issues.append(
                    f"ë„ˆë¬´ ê°€ê¹Œìš´ POI: {poi1.get('id')} - {poi2.get('id')} "
                    f"(ê±°ë¦¬: {distance:.6f})"
                )
    
    return issues[:5]  # ìƒìœ„ 5ê°œë§Œ ë°˜í™˜

def calculate_quality_score(valid_count, total_count, issues_count, category_distribution):
    """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
    if total_count == 0:
        return 0
    
    # ê¸°ë³¸ ì ìˆ˜ (ìœ íš¨ì„±)
    validity_score = (valid_count / total_count) * 70
    
    # ì´ìŠˆ ì ìˆ˜ (ì ì„ìˆ˜ë¡ ì¢‹ìŒ)
    issue_penalty = min(issues_count * 2, 20)
    issue_score = 20 - issue_penalty
    
    # ì¹´í…Œê³ ë¦¬ ê· í˜• ì ìˆ˜
    balance_score = calculate_balance_score(category_distribution)
    
    total_score = validity_score + issue_score + balance_score
    return min(100, max(0, total_score))

def calculate_balance_score(distribution):
    """ì¹´í…Œê³ ë¦¬ ê· í˜• ì ìˆ˜ ê³„ì‚°"""
    if not distribution:
        return 0
    
    percentages = [data['percentage'] for data in distribution.values()]
    
    # ì´ìƒì ì¸ ê· í˜• (ê° ì¹´í…Œê³ ë¦¬ 16.67%)
    ideal_percentage = 100 / len(VALID_CATEGORIES)
    
    # í¸ì°¨ ê³„ì‚°
    variance = sum((p - ideal_percentage)**2 for p in percentages) / len(percentages)
    
    # ì ìˆ˜ ë³€í™˜ (í¸ì°¨ê°€ ì ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
    balance_score = max(0, 10 - variance / 10)
    
    return balance_score

def get_quality_grade(score):
    """í’ˆì§ˆ ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
    if score >= 95:
        return "A+"
    elif score >= 90:
        return "A"
    elif score >= 85:
        return "B+"
    elif score >= 80:
        return "B"
    elif score >= 75:
        return "C+"
    elif score >= 70:
        return "C"
    else:
        return "D"

def save_quality_report(report):
    """í’ˆì§ˆ ë³´ê³ ì„œ ì €ì¥"""
    try:
        os.makedirs('claudedocs', exist_ok=True)
        
        # ìƒì„¸ ë³´ê³ ì„œ
        with open('claudedocs/quality_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ê°„ë‹¨í•œ ìš”ì•½
        summary = f"""# ë°ì´í„° í’ˆì§ˆ ë³´ê³ ì„œ

**ê²€ì‚¬ ì‹œê°„**: {report['timestamp']}
**ì´ POI**: {report['total_pois']}ê°œ
**ìœ íš¨ POI**: {report['valid_pois']}ê°œ
**í’ˆì§ˆ ì ìˆ˜**: {report['score']:.1f}%
**ë“±ê¸‰**: {report['grade']}

## ì¹´í…Œê³ ë¦¬ ë¶„í¬
"""
        
        for category, data in report['category_distribution'].items():
            summary += f"- {category}: {data['count']}ê°œ ({data['percentage']}%)\n"
        
        if report['issues']:
            summary += "\n## ì£¼ìš” ì´ìŠˆ\n"
            for issue in report['issues'][:5]:
                summary += f"- {issue}\n"
        
        with open('claudedocs/quality_summary.md', 'w', encoding='utf-8') as f:
            f.write(summary)
        
        print("ğŸ“„ í’ˆì§ˆ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âš ï¸ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    print("ğŸ” ë¯¸ì•¼ì½”ì§€ë§ˆ POI ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬")
    print("=" * 50)
    
    run_quality_check()
```

---

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### ì´ˆê¸° ì„¤ì • (í•œ ë²ˆë§Œ)
```bash
# 1. ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv poi_sync_env
poi_sync_env\Scripts\activate

# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install gspread google-auth pandas schedule

# 3. ì„¤ì • íŒŒì¼ ìˆ˜ì •
# sheets_config.pyì—ì„œ SPREADSHEET_ID ì„¤ì •

# 4. ì´ˆê¸° ì—…ë¡œë“œ
python upload_to_sheets.py
```

### ì¼ìƒ ì‚¬ìš©
```bash
# ìŠ¤í”„ë ˆë“œì‹œíŠ¸ â†’ JSON ë™ê¸°í™”
python download_from_sheets.py

# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘
python monitor_changes.py

# ìë™ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
python sync_scheduler.py

# í’ˆì§ˆ ê²€ì‚¬
python validation_utils.py
```

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

ì´ì œ **ì™„ë²½í•œ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—°ë™ ì‹œìŠ¤í…œ**ì´ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤!

**ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥**:
1. Google Cloud ì„¤ì • (10ë¶„)
2. ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„± (5ë¶„)  
3. Python í™˜ê²½ ì„¤ì • (10ë¶„)
4. ì²« ì—…ë¡œë“œ ì‹¤í–‰ (5ë¶„)

**í–¥í›„ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ì‹œì—ë„ ì´ ì‹œìŠ¤í…œì„ í™•ì¥**í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ‰ **100ê°œ POI ë°ì´í„°**ì™€ í•¨ê»˜ ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì™„ì „í•œ ë™ê¸°í™” ì‹œìŠ¤í…œì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!