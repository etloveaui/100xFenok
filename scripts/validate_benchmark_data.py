#!/usr/bin/env python3
"""
100xFenok Benchmarks ë°¸ë¥˜ì—ì´ì…˜ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
"""
import json
import os
from datetime import datetime
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Any

# ë°ì´í„° ê²½ë¡œ
DATA_DIR = Path("source/100xFenok/data/benchmarks")
FILES = ["us.json", "us_sectors.json", "micro_sectors.json", "developed.json", "emerging.json", "msci.json"]
REQUIRED_FIELDS = ["date", "px_last", "best_eps", "best_pe_ratio", "px_to_book_ratio", "roe"]

class DataValidator:
    def __init__(self):
        self.results = defaultdict(dict)
        self.issues = defaultdict(list)
        
    def load_file(self, filename: str) -> Dict:
        """JSON íŒŒì¼ ë¡œë“œ"""
        path = DATA_DIR / filename
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def validate_structure(self, filename: str, data: Dict) -> Dict:
        """ê¸°ë³¸ êµ¬ì¡° ê²€ì¦"""
        issues = []
        
        # metadata ì²´í¬
        if 'metadata' not in data:
            issues.append("âŒ metadata í•„ë“œ ëˆ„ë½")
        else:
            meta = data['metadata']
            required_meta = ['version', 'generated', 'source', 'update_frequency']
            for field in required_meta:
                if field not in meta:
                    issues.append(f"âŒ metadata.{field} ëˆ„ë½")
        
        # sections ì²´í¬
        if 'sections' not in data:
            issues.append("âŒ sections í•„ë“œ ëˆ„ë½")
            return {'valid': False, 'issues': issues}
        
        sections = data['sections']
        section_count = len(sections)
        
        return {
            'valid': len(issues) == 0,
            'section_count': section_count,
            'sections': list(sections.keys()),
            'issues': issues
        }
    
    def validate_fields(self, filename: str, data: Dict) -> Dict:
        """í•„ë“œ ì™„ê²°ì„± ê²€ì¦"""
        field_stats = defaultdict(lambda: {'missing': 0, 'null': 0, 'total': 0})
        
        for section_key, section in data['sections'].items():
            if 'data' not in section:
                self.issues[filename].append(f"âš ï¸ {section_key}: data ë°°ì—´ ëˆ„ë½")
                continue
            
            for i, record in enumerate(section['data']):
                for field in REQUIRED_FIELDS:
                    field_stats[field]['total'] += 1
                    
                    if field not in record:
                        field_stats[field]['missing'] += 1
                    elif record[field] is None:
                        field_stats[field]['null'] += 1
        
        return dict(field_stats)
    
    def validate_data_quality(self, filename: str, data: Dict) -> Dict:
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦ (ì´ìƒê°’, ìŒìˆ˜ ë“±)"""
        anomalies = defaultdict(list)
        
        for section_key, section in data['sections'].items():
            if 'data' not in section:
                continue
            
            for i, record in enumerate(section['data']):
                date_str = record.get('date', 'unknown')
                
                # px_last ìŒìˆ˜ ì²´í¬
                px_last = record.get('px_last')
                if px_last is not None and px_last <= 0:
                    anomalies['negative_price'].append(f"{section_key}[{date_str}]: px_last={px_last}")
                
                # best_pe_ratio ìŒìˆ˜ ë˜ëŠ” ê·¹ë‹¨ê°’
                pe = record.get('best_pe_ratio')
                if pe is not None:
                    if pe < 0:
                        anomalies['negative_pe'].append(f"{section_key}[{date_str}]: PE={pe}")
                    elif pe > 1000:
                        anomalies['extreme_pe'].append(f"{section_key}[{date_str}]: PE={pe}")
                
                # px_to_book_ratio ìŒìˆ˜ ë˜ëŠ” ê·¹ë‹¨ê°’
                pb = record.get('px_to_book_ratio')
                if pb is not None:
                    if pb < 0:
                        anomalies['negative_pb'].append(f"{section_key}[{date_str}]: PB={pb}")
                    elif pb > 100:
                        anomalies['extreme_pb'].append(f"{section_key}[{date_str}]: PB={pb}")
                
                # roe ë²”ìœ„ ì²´í¬ (ì¼ë°˜ì ìœ¼ë¡œ -1 ~ 1)
                roe = record.get('roe')
                if roe is not None:
                    if roe < -1 or roe > 1:
                        anomalies['roe_out_of_range'].append(f"{section_key}[{date_str}]: ROE={roe}")
        
        return dict(anomalies)
    
    def validate_date_range(self, filename: str, data: Dict) -> Dict:
        """ë‚ ì§œ ë²”ìœ„ ë° ë¹ˆë„ ê²€ì¦"""
        date_info = {}
        
        for section_key, section in data['sections'].items():
            if 'data' not in section or len(section['data']) == 0:
                continue
            
            dates = [record['date'] for record in section['data'] if 'date' in record]
            if not dates:
                continue
            
            dates_sorted = sorted(dates)
            
            # ë‚ ì§œ ê°„ê²© ê³„ì‚° (ì£¼ê°„ ë°ì´í„° ê°€ì •: 7ì¼)
            gaps = []
            for i in range(1, len(dates_sorted)):
                d1 = datetime.fromisoformat(dates_sorted[i-1])
                d2 = datetime.fromisoformat(dates_sorted[i])
                gap_days = (d2 - d1).days
                if gap_days > 14:  # 2ì£¼ ì´ìƒ ê°„ê²©
                    gaps.append(f"{dates_sorted[i-1]} â†’ {dates_sorted[i]} ({gap_days}ì¼)")
            
            date_info[section_key] = {
                'start': dates_sorted[0],
                'end': dates_sorted[-1],
                'count': len(dates),
                'large_gaps': gaps[:5] if gaps else []  # ìƒìœ„ 5ê°œë§Œ
            }
        
        return date_info
    
    def cross_file_consistency(self, all_data: Dict[str, Dict]) -> Dict:
        """í¬ë¡œìŠ¤ íŒŒì¼ ì¼ê´€ì„± ê²€ì‚¬"""
        consistency_issues = []
        
        # ë‚ ì§œ ë²”ìœ„ ì¼ê´€ì„±
        date_ranges = {}
        for filename, data in all_data.items():
            for section_key, section in data['sections'].items():
                if 'data' in section and section['data']:
                    dates = [r['date'] for r in section['data'] if 'date' in r]
                    if dates:
                        date_ranges[f"{filename}:{section_key}"] = (min(dates), max(dates))
        
        # ì „ì²´ ë‚ ì§œ ë²”ìœ„
        all_starts = [r[0] for r in date_ranges.values()]
        all_ends = [r[1] for r in date_ranges.values()]
        
        global_start = min(all_starts) if all_starts else None
        global_end = max(all_ends) if all_ends else None
        
        # ë²”ìœ„ ì°¨ì´ê°€ í° ê²½ìš°
        for key, (start, end) in date_ranges.items():
            if global_start and start > global_start:
                start_diff = (datetime.fromisoformat(start) - datetime.fromisoformat(global_start)).days
                if start_diff > 365:  # 1ë…„ ì´ìƒ ì°¨ì´
                    consistency_issues.append(f"âš ï¸ {key}: ì‹œì‘ì¼ì´ ì „ì²´ë³´ë‹¤ {start_diff}ì¼ ëŠ¦ìŒ")
            
            if global_end and end < global_end:
                end_diff = (datetime.fromisoformat(global_end) - datetime.fromisoformat(end)).days
                if end_diff > 30:  # 1ê°œì›” ì´ìƒ ì°¨ì´
                    consistency_issues.append(f"âš ï¸ {key}: ì¢…ë£Œì¼ì´ ì „ì²´ë³´ë‹¤ {end_diff}ì¼ ì´ë¦„")
        
        return {
            'global_range': (global_start, global_end),
            'section_count': len(date_ranges),
            'issues': consistency_issues[:10]  # ìƒìœ„ 10ê°œë§Œ
        }

def main():
    print("=" * 80)
    print("100xFenok Benchmarks ë°¸ë¥˜ì—ì´ì…˜ ë°ì´í„° í’ˆì§ˆ ê²€ì¦")
    print("=" * 80)
    print()
    
    validator = DataValidator()
    all_data = {}
    
    # 1. íŒŒì¼ë³„ ê²€ì¦
    for filename in FILES:
        print(f"\nğŸ“ {filename}")
        print("-" * 80)
        
        try:
            data = validator.load_file(filename)
            all_data[filename] = data
            
            # êµ¬ì¡° ê²€ì¦
            struct_result = validator.validate_structure(filename, data)
            print(f"âœ… êµ¬ì¡°: {struct_result['section_count']}ê°œ ì„¹ì…˜")
            if struct_result['issues']:
                for issue in struct_result['issues']:
                    print(f"  {issue}")
            
            # í•„ë“œ ê²€ì¦
            field_result = validator.validate_fields(filename, data)
            print(f"\nğŸ“Š í•„ë“œ í†µê³„:")
            for field, stats in field_result.items():
                missing_pct = (stats['missing'] / stats['total'] * 100) if stats['total'] > 0 else 0
                null_pct = (stats['null'] / stats['total'] * 100) if stats['total'] > 0 else 0
                print(f"  - {field}: ì „ì²´={stats['total']:,}, ëˆ„ë½={stats['missing']} ({missing_pct:.2f}%), null={stats['null']} ({null_pct:.2f}%)")
            
            # ë°ì´í„° í’ˆì§ˆ
            quality_result = validator.validate_data_quality(filename, data)
            if quality_result:
                print(f"\nâš ï¸ ì´ìƒê°’ íƒì§€:")
                for anomaly_type, cases in quality_result.items():
                    print(f"  - {anomaly_type}: {len(cases)}ê±´")
                    for case in cases[:3]:  # ìƒìœ„ 3ê°œë§Œ
                        print(f"    Â· {case}")
            
            # ë‚ ì§œ ë²”ìœ„
            date_result = validator.validate_date_range(filename, data)
            print(f"\nğŸ“… ë‚ ì§œ ë²”ìœ„:")
            for section_key, info in list(date_result.items())[:3]:  # ìƒìœ„ 3ê°œë§Œ
                print(f"  - {section_key}: {info['start']} ~ {info['end']} ({info['count']}í¬ì¸íŠ¸)")
                if info['large_gaps']:
                    print(f"    âš ï¸ í° ê°„ê²©: {len(info['large_gaps'])}ê±´")
                    
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
    
    # 2. í¬ë¡œìŠ¤ íŒŒì¼ ì¼ê´€ì„±
    print("\n\n" + "=" * 80)
    print("í¬ë¡œìŠ¤ íŒŒì¼ ì¼ê´€ì„± ê²€ì¦")
    print("=" * 80)
    
    consistency = validator.cross_file_consistency(all_data)
    print(f"\nì „ì²´ ë‚ ì§œ ë²”ìœ„: {consistency['global_range'][0]} ~ {consistency['global_range'][1]}")
    print(f"ì „ì²´ ì„¹ì…˜ ìˆ˜: {consistency['section_count']}")
    
    if consistency['issues']:
        print(f"\nâš ï¸ ì¼ê´€ì„± ì´ìŠˆ ({len(consistency['issues'])}ê±´):")
        for issue in consistency['issues']:
            print(f"  {issue}")
    
    print("\n\nê²€ì¦ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
